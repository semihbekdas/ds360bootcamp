# Hafta 7: Metin Ä°ÅŸleme ve NLP Optimizasyonu

Bu proje TÃ¼rkÃ§e saÄŸlÄ±k verilerinde metin iÅŸleme, doÄŸal dil iÅŸleme (NLP) ve model optimizasyonu tekniklerini gÃ¶sterir.

## ğŸ“ Proje YapÄ±sÄ±

```
hafta7/
â”œâ”€â”€ data/                          # Veri dosyalarÄ±
â”‚   â”œâ”€â”€ synthetic_health_data.py   # Sentetik saÄŸlÄ±k verisi Ã¼reteci
â”‚   â””â”€â”€ synthetic_health_data.csv  # Ãœretilen veri seti
â”œâ”€â”€ examples/                      # Ã–rnek scriptler
â”‚   â”œâ”€â”€ 01_text_cleaning_tokenization.py  # Metin temizleme ve tokenization
â”‚   â”œâ”€â”€ 02_tfidf_analysis.py       # TF-IDF analizi
â”‚   â”œâ”€â”€ 03_bert_analysis.py        # BERT tabanlÄ± analiz
â”‚   â””â”€â”€ 04_model_optimization.py   # Model optimizasyonu
â”œâ”€â”€ src/                          # Ana kaynak kodlarÄ±
â”‚   â””â”€â”€ pii_masking.py            # PII maskeleme
â”œâ”€â”€ api/                          # FastAPI servisi
â”‚   â”œâ”€â”€ main.py                   # API ana dosyasÄ±
â”‚   â””â”€â”€ test_api.py              # API test scriptleri
â”œâ”€â”€ requirements.txt              # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â””â”€â”€ README.md                    # Bu dosya
```

## ğŸš€ Kurulum

### 1. Sanal Ortam OluÅŸturma ve Aktivasyon

```bash
# Hafta 7 dizinine git
cd hafta7

# Sanal ortam oluÅŸtur
python -m venv venv

# Sanal ortamÄ± aktif et
# macOS/Linux:
source venv/bin/activate
# Windows:
# venv\Scripts\activate

# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt
```

### 2. NLTK Verilerini Ä°ndirme (Ä°lk KullanÄ±m)

```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
```

### 3. SpaCy Ä°ngilizce Modeli (PII Maskeleme iÃ§in gerekli)

```bash
python -m spacy download en_core_web_sm
```

### 4. SpaCy TÃ¼rkÃ§e Modeli (Opsiyonel)

```bash
python -m spacy download tr_core_news_sm
```

## ğŸ“Š Veri Ãœretimi

Sentetik saÄŸlÄ±k verisi oluÅŸturmak iÃ§in:

```bash
python data/synthetic_health_data.py
```

Bu script `data/synthetic_health_data.csv` dosyasÄ±nÄ± oluÅŸturur ve aÅŸaÄŸÄ±daki bilgileri iÃ§erir:
- Hasta bilgileri (ad, soyad, TC kimlik, telefon, email)
- SaÄŸlÄ±k verileri (tanÄ±, doktor, hastane, kan grubu)
- Adres ve notlar

## ğŸ”§ Ã–rneklerin Ã‡alÄ±ÅŸtÄ±rÄ±lmasÄ±

### 1. Metin Temizleme ve Tokenization

```bash
python examples/01_text_cleaning_tokenization.py
```

**Ã–zellikler:**
- TÃ¼rkÃ§e karakterleri koruyarak metin temizleme
- NLTK ve SpaCy ile tokenization
- Stop word filtreleme
- CÃ¼mle bÃ¶lÃ¼tleme

### 2. TF-IDF Analizi

```bash
python examples/02_tfidf_analysis.py
```

**Ã–zellikler:**
- Terim-frekans analizi
- DokÃ¼man benzerliÄŸi hesaplama
- K-means kÃ¼meleme
- En Ã¶nemli terimlerin gÃ¶rselleÅŸtirilmesi

### 3. BERT TabanlÄ± Analiz

```bash
python examples/03_bert_analysis.py
```

**Ã–zellikler:**
- TÃ¼rkÃ§e BERT embeddings
- Semantik benzerlik analizi
- PCA ile boyut azaltma
- Duygu analizi (opsiyonel)

### 4. Model Optimizasyonu

```bash
python examples/04_model_optimization.py
```

**Ã–zellikler:**
- Model boyutu karÅŸÄ±laÅŸtÄ±rmasÄ±
- DistilBERT ile hÄ±zlandÄ±rma
- Quantization teknikleri
- Embeddings sÄ±kÄ±ÅŸtÄ±rma

## ğŸ” PII Maskeleme

KiÅŸisel bilgileri maskelemek iÃ§in:

```bash
python src/pii_masking.py
```

**Maskelenen Bilgiler:**
- TC Kimlik numaralarÄ± â†’ `[TC_KIMLIK]`
- Telefon numaralarÄ± â†’ `[TELEFON]` / `<PHONE_NUMBER>`
- E-mail adresleri â†’ `[EMAIL]` / `<EMAIL_ADDRESS>`
- Doktor/hasta isimleri â†’ `[DOKTOR_ADI]` / `<PERSON>`
- Adres bilgileri â†’ `[ADRES]`
- IBAN numaralarÄ± â†’ `[IBAN]`

**Ä°ki FarklÄ± YÃ¶ntem:**
- **Regex**: TÃ¼rkÃ§e odaklÄ± pattern matching
- **Presidio**: AI tabanlÄ± geliÅŸmiÅŸ PII tanÄ±ma

## ğŸŒ FastAPI Servisi

### API BaÅŸlatma

```bash
# Ana dizinden Ã§alÄ±ÅŸtÄ±r
python api/main.py

# Veya uvicorn ile
uvicorn api.main:app --host 0.0.0.0 --port 8000
```

### API Testleri

```bash
# API'nin Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olduktan sonra
python api/test_api.py
```

### API Endpoints

- `GET /` - Ana sayfa
- `POST /clean-text` - Metin temizleme
- `POST /tfidf-analysis` - TF-IDF analizi
- `POST /similarity` - Benzerlik analizi
- `POST /bert-embeddings` - BERT embeddings
- `POST /mask-pii` - PII maskeleme
- `POST /health-data-analysis` - KapsamlÄ± saÄŸlÄ±k verisi analizi
- `GET /health` - Servis durumu

### Ã–rnek API KullanÄ±mÄ±

```python
import requests

# Metin temizleme
response = requests.post(
    "http://localhost:8000/clean-text",
    json={"text": "Dr. Ahmet YILMAZ hastayÄ± muayene etti!!!"}
)

# TF-IDF analizi
response = requests.post(
    "http://localhost:8000/tfidf-analysis",
    json={
        "texts": [
            "Hasta hipertansiyon tedavisi gÃ¶rÃ¼yor",
            "Diyabet hastasÄ± insulin kullanÄ±yor"
        ]
    }
)

# PII maskeleme
response = requests.post(
    "http://localhost:8000/mask-pii",
    json={
        "text": "TC: 12345678901, Tel: 0532-123-4567",
        "method": "regex"
    }
)
```

## ğŸ“ˆ Performans Optimizasyonu

### Model Boyutu Azaltma
- **BERT**: ~440MB â†’ **DistilBERT**: ~250MB (%43 azaltma)
- **Quantization**: Ek %20-30 boyut azaltma
- **Embedding sÄ±kÄ±ÅŸtÄ±rma**: %50-70 boyut azaltma

### HÄ±z Optimizasyonu
- **DistilBERT**: 2-3x daha hÄ±zlÄ±
- **Batch processing**: BÃ¼yÃ¼k veri setleri iÃ§in
- **GPU kullanÄ±mÄ±**: CUDA desteÄŸi ile

## ğŸ› ï¸ GeliÅŸtirme

### Yeni Ã–zellik Ekleme

1. `examples/` dizinine yeni script ekleyin
2. `api/main.py` dosyasÄ±na yeni endpoint ekleyin
3. `requirements.txt` dosyasÄ±nÄ± gÃ¼ncelleyin
4. Test script'ini `api/test_api.py` dosyasÄ±na ekleyin

### Test Etme

```bash
# TÃ¼m scriptleri test et
python examples/01_text_cleaning_tokenization.py
python examples/02_tfidf_analysis.py
python examples/03_bert_analysis.py
python examples/04_model_optimization.py
python src/pii_masking.py

# API testleri
python api/test_api.py
```

## ğŸ“‹ Ã–nemli Notlar

### BaÄŸÄ±mlÄ±lÄ±k Ã‡akÄ±ÅŸmalarÄ±
- TÃ¼m baÄŸÄ±mlÄ±lÄ±klar sabit sÃ¼rÃ¼mlerle belirtilmiÅŸtir
- Sanal ortam kullanÄ±mÄ± zorunludur
- Conflict olmasÄ± durumunda `requirements.txt` dosyasÄ±nÄ± gÃ¼ncelleyin

### GPU KullanÄ±mÄ±
- PyTorch CPU versiyonu yÃ¼klÃ¼dÃ¼r
- GPU kullanÄ±mÄ± iÃ§in PyTorch CUDA versiyonunu yÃ¼kleyin
- Model yÃ¼kleme sÄ±rasÄ±nda GPU kontrolÃ¼ otomatik yapÄ±lÄ±r

### Bellek KullanÄ±mÄ±
- BERT modelleri yÃ¼ksek bellek kullanÄ±r (~2-4GB)
- BÃ¼yÃ¼k veri setleri iÃ§in batch processing kullanÄ±n
- Model optimizasyonu ile bellek kullanÄ±mÄ± azaltÄ±labilir

## ğŸ” Troubleshooting

### YaygÄ±n Hatalar

1. **Model yÃ¼klenmiyor**: Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin
2. **NLTK verisi bulunamÄ±yor**: `nltk.download()` komutlarÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n
3. **API Ã§alÄ±ÅŸmÄ±yor**: Port 8000'in aÃ§Ä±k olduÄŸunu kontrol edin
4. **Bellek yetersiz**: Daha kÃ¼Ã§Ã¼k batch size kullanÄ±n

### Ã‡Ã¶zÃ¼mler

```bash
# BaÄŸÄ±mlÄ±lÄ±klarÄ± yeniden yÃ¼kle
pip install --force-reinstall -r requirements.txt

# Cache temizle
pip cache purge

# Sanal ortamÄ± yeniden oluÅŸtur
rm -rf venv
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

## ğŸ“š Kaynaklar

- [Transformers Documentation](https://huggingface.co/docs/transformers/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [NLTK Documentation](https://www.nltk.org/)
- [SpaCy Turkish Model](https://spacy.io/models/tr)

## ğŸ“„ Lisans

Bu proje eÄŸitim amaÃ§lÄ±dÄ±r ve MIT lisansÄ± altÄ±nda daÄŸÄ±tÄ±lmaktadÄ±r.
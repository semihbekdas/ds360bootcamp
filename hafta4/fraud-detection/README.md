# Hafta 4: Finans Sprinti - Fraud Detection ğŸ¦

## ğŸ“‹ Konu BaÅŸlÄ±klarÄ± ve Ã–ÄŸrenilecekler

### 1. ğŸ¯ Outlier Detection
- **Isolation Forest**: Anomaly detection iÃ§in ensemble method
- **Local Outlier Factor (LOF)**: Density-based outlier detection
- **KarÅŸÄ±laÅŸtÄ±rma**: Supervised vs Unsupervised yaklaÅŸÄ±mlar
- **Hyperparameter tuning**: contamination, n_neighbors optimizasyonu

### 2. ğŸ”§ Feature Scaling ve Encoding
- **Scaling Methods**: StandardScaler vs RobustScaler vs MinMaxScaler
- **Categorical Encoding**: OneHot vs Label vs Ordinal
- **Feature Engineering**: Log transformation, interaction features
- **Missing Value Handling**: Imputation strategies
- **Class Imbalance**: SMOTE, ADASYN, SMOTETomek

### 3. ğŸ“Š ROC-AUC ve PR-AUC Metrikleri
- **ROC-AUC**: True Positive Rate vs False Positive Rate
- **PR-AUC**: Precision vs Recall (imbalanced data iÃ§in kritik)
- **Threshold Optimization**: Business cost minimization
- **Confusion Matrix**: TP, FP, TN, FN analizi
- **Business Metrics**: Cost-benefit analysis

### 4. ğŸ” Model AÃ§Ä±klanabilirlik
- **SHAP (SHapley Additive exPlanations)**:
  - TreeExplainer: Tree-based modeller iÃ§in
  - KernelExplainer: Model-agnostic yaklaÅŸÄ±m
  - Feature importance ve dependence plots
- **LIME (Local Interpretable Model-agnostic Explanations)**:
  - Local aÃ§Ä±klamalar
  - Tabular explainer
- **Global vs Local aÃ§Ä±klamalar**
- **Fraud pattern analizi**

### 5. ğŸš€ CI/CD Pipeline ve Deployment
- **Data Validation**: Schema ve quality checks
- **Model Training**: Automated retraining
- **Performance Monitoring**: Drift detection
- **A/B Testing**: Model comparison
- **Production Deployment**: Staging â†’ Production
- **Security**: Model signing, access control

## ğŸ¯ KullanÄ±lan Dataset: Credit Card Fraud Detection

Bu proje **gerÃ§ek dÃ¼nya fraud detection** problemini simÃ¼le etmek iÃ§in en uygun dataset'i kullanÄ±r:

### Dataset Ã–zellikleri
- **Boyut**: 284,807 iÅŸlem
- **Imbalance**: %99.83 Normal, %0.17 Fraud (gerÃ§ekÃ§i oran)
- **Features**: 30 kolon
  - `V1-V28`: PCA ile dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ gizli features (privacy iÃ§in)
  - `Time`: Ä°ÅŸlem zamanÄ± (saniye cinsinden)
  - `Amount`: Ä°ÅŸlem tutarÄ±
  - `Class`: 0=Normal, 1=Fraud (target variable)

### Neden Bu Dataset?
- âœ… **GerÃ§ekÃ§i imbalance**: Production fraud rate'ini yansÄ±tÄ±r
- âœ… **Preprocessed**: PCA ile privacy korunmuÅŸ
- âœ… **TemizlenmiÅŸ**: Missing value yok
- âœ… **HÄ±zlÄ± training**: Makul boyut
- âœ… **EÄŸitim dostu**: TÃ¼m konular iÃ§in ideal

## ğŸ—ï¸ Proje YapÄ±sÄ±

```
hafta4/fraud-detection/
â”œâ”€â”€ src/                           # Ana kaynak kodlar
â”‚   â”œâ”€â”€ outlier_detection.py       # Isolation Forest & LOF
â”‚   â”œâ”€â”€ preprocessing.py           # Feature scaling & encoding
â”‚   â”œâ”€â”€ evaluation.py             # ROC-AUC, PR-AUC metrikleri
â”‚   â”œâ”€â”€ explainability.py         # SHAP/LIME aÃ§Ä±klamalarÄ±
â”‚   â””â”€â”€ pipeline.py               # End-to-end pipeline
â”œâ”€â”€ tests/                         # Unit testler
â”‚   â””â”€â”€ test_pipeline.py          
â”œâ”€â”€ .github/workflows/             # CI/CD pipeline
â”‚   â””â”€â”€ ci_cd.yml                 # GitHub Actions
â”œâ”€â”€ config/                        # KonfigÃ¼rasyon dosyalarÄ±
â”‚   â””â”€â”€ config.yaml               # Model ve training parametreleri
â”œâ”€â”€ data/                          # Veri klasÃ¶rleri
â”‚   â”œâ”€â”€ raw/                      # Ham veri
â”‚   â””â”€â”€ processed/                # Ä°ÅŸlenmiÅŸ veri
â”œâ”€â”€ models/                        # EÄŸitilmiÅŸ modeller
â”œâ”€â”€ logs/                          # Log dosyalarÄ±
â”œâ”€â”€ notebooks/                     # Jupyter notebooks (analiz iÃ§in)
â”œâ”€â”€ download_data.py              # Dataset indirme utility
â”œâ”€â”€ run_demo.py                   # Interaktif demo
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # Bu dosya
```

## ğŸ”§ Kurulum ve Setup

### 1. Environment Setup
```bash
# Proje klasÃ¶rÃ¼ne git
cd hafta4/fraud-detection

# Virtual environment oluÅŸtur (Ã¶nerilen)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Dependencies kur
pip install -r requirements.txt
```

### 2. Dataset Ä°ndirme
```python
# YÃ¶ntem 1: Python script ile
import kagglehub
path = kagglehub.dataset_download("mlg-ulb/creditcardfraud")
print("Path to dataset files:", path)

# YÃ¶ntem 2: Download utility ile
python download_data.py

# YÃ¶ntem 3: Pipeline ile otomatik
python src/pipeline.py --use_kagglehub --save_models
```

### 3. HÄ±zlÄ± Test
```bash
# Demo Ã§alÄ±ÅŸtÄ±r (synthetic data ile)
python run_demo.py

# GerÃ§ek data ile training
python src/pipeline.py --data data/raw/creditcard_fraud.csv --save_models
```

## ğŸ® Demo ve Ã–rnekler

### 1. Ä°nteraktif Demo
```bash
python run_demo.py
```
**Menu seÃ§enekleri:**
- Preprocessing demo
- Outlier detection demo  
- Evaluation metrikleri
- Model aÃ§Ä±klanabilirlik
- Full pipeline
- Model karÅŸÄ±laÅŸtÄ±rmasÄ±
- Business metrics analizi

### 2. Outlier Detection
```python
from src.outlier_detection import OutlierDetector

# Isolation Forest
detector = OutlierDetector(contamination=0.002)  # %0.2 fraud oranÄ±
detector.fit_isolation_forest(X_train)
predictions = detector.predict_isolation_forest(X_test)

# Performance evaluation
detector.evaluate_performance(X_test, y_test, 'isolation_forest')
```

### 3. Feature Preprocessing
```python
from src.preprocessing import FeaturePreprocessor, ImbalanceHandler

# Preprocessing
preprocessor = FeaturePreprocessor(
    scaling_method='robust',  # Outlier'lara dayanÄ±klÄ±
    encoding_method='onehot'
)
X_processed = preprocessor.fit_transform(X_train)

# Imbalance handling
X_balanced, y_balanced = ImbalanceHandler.apply_smote(X_train, y_train)
```

### 4. Model Evaluation
```python
from src.evaluation import FraudEvaluator

evaluator = FraudEvaluator(model, "Random Forest")
results = evaluator.evaluate_binary_classification(X_test, y_test)

# ROC ve PR curves
evaluator.plot_roc_curve(X_test, y_test)
evaluator.plot_precision_recall_curve(X_test, y_test)

# Threshold optimization
optimal_threshold = evaluator.plot_threshold_analysis(X_test, y_test)
```

### 5. Model AÃ§Ä±klanabilirlik
```python
from src.explainability import ModelExplainer

explainer = ModelExplainer(model, X_train, feature_names, ['Normal', 'Fraud'])

# SHAP analysis
explainer.initialize_shap('tree')
shap_values = explainer.compute_shap_values(X_test)
explainer.plot_shap_summary(X_test)

# Individual explanations
explainer.plot_shap_waterfall(X_test, instance_idx=0)

# LIME comparison
explainer.explain_instance_lime(X_test, instance_idx=0)
```

## ğŸ“Š Beklenen SonuÃ§lar ve Ã–ÄŸrenim Hedefleri

### 1. Outlier Detection Performance
- **Isolation Forest**: ROC-AUC ~0.85-0.90
- **LOF**: ROC-AUC ~0.80-0.85
- **Hybrid approach**: Ensemble of methods

### 2. Supervised Learning Benchmarks
- **Random Forest**: ROC-AUC ~0.95+, PR-AUC ~0.75+
- **Logistic Regression**: ROC-AUC ~0.93+, PR-AUC ~0.65+
- **Gradient Boosting**: ROC-AUC ~0.96+, PR-AUC ~0.80+

### 3. Feature Importance Insights
- **Time patterns**: Gece fraud'larÄ± daha yÃ¼ksek
- **Amount patterns**: KÃ¼Ã§Ã¼k ve Ã§ok bÃ¼yÃ¼k miktarlar risky
- **PCA features**: V4, V11, V12 genellikle Ã¶nemli

### 4. Business Metrics
- **Optimal threshold**: ~0.3-0.4 (cost minimization iÃ§in)
- **Cost reduction**: %60-80 compared to random checking
- **False positive rate**: <%5 (customer experience iÃ§in)

## ğŸ¯ Learning Path ve Exercises

### BaÅŸlangÄ±Ã§ Seviyesi
1. **Dataset exploration**: EDA ve basic statistics
2. **Simple outlier detection**: Isolation Forest ile baÅŸla
3. **Basic preprocessing**: Scaling ve encoding
4. **Model training**: Single algorithm (Random Forest)
5. **Basic evaluation**: ROC-AUC ve confusion matrix

### Orta Seviye
1. **Multiple outlier methods**: IF + LOF karÅŸÄ±laÅŸtÄ±rmasÄ±
2. **Advanced preprocessing**: Feature engineering
3. **Imbalance handling**: SMOTE ile class balancing
4. **Threshold optimization**: Business cost minimization
5. **Model comparison**: Multiple algorithms

### Ä°leri Seviye
1. **Ensemble methods**: Multiple outlier detector fusion
2. **Custom preprocessing pipeline**: Domain-specific features
3. **Advanced evaluation**: PR-AUC focus, cost-sensitive metrics
4. **Model explainability**: SHAP + LIME comprehensive analysis
5. **Production pipeline**: CI/CD ile automated deployment

### Expert Seviye
1. **Real-time detection**: Streaming data processing
2. **Model drift detection**: Performance monitoring
3. **A/B testing**: Model comparison in production
4. **Custom explainability**: Domain-specific explanations
5. **End-to-end MLOps**: Complete production system

## ğŸ”¥ Advanced Features

### 1. Hyperparameter Optimization
```python
# Grid search for optimal parameters
from sklearn.model_selection import GridSearchCV

param_grid = {
    'contamination': [0.001, 0.002, 0.005],
    'n_estimators': [50, 100, 200]
}
```

### 2. Ensemble Methods
```python
# Combine multiple outlier detectors
ensemble_prediction = (if_pred + lof_pred + svm_pred) / 3
```

### 3. Real-time Scoring
```python
# Fast inference pipeline
@app.route('/predict', methods=['POST'])
def predict_fraud():
    features = preprocess(request.json)
    prediction = model.predict_proba(features)[0][1]
    return {'fraud_probability': prediction}
```

### 4. Model Monitoring
```python
# Performance drift detection
def detect_drift(model, X_new, threshold=0.1):
    current_auc = roc_auc_score(y_true, model.predict_proba(X_new)[:, 1])
    return abs(baseline_auc - current_auc) > threshold
```

## ğŸš€ Production Deployment

### 1. CI/CD Pipeline
```yaml
# .github/workflows/ci_cd.yml
- Data validation
- Model training  
- Performance testing
- Security scanning
- Staging deployment
- Production deployment
- Monitoring setup
```

### 2. Model Serving
```python
# FastAPI ile REST API
from fastapi import FastAPI
app = FastAPI()

@app.post("/predict")
async def predict_transaction(transaction: TransactionModel):
    # Preprocessing + Prediction + Logging
    return PredictionResponse(is_fraud=prediction, confidence=confidence)
```

### 3. Monitoring Dashboard
- **Performance metrics**: ROC-AUC, PR-AUC trends
- **Business metrics**: False positive rate, cost savings
- **Data drift**: Feature distribution changes
- **Model drift**: Performance degradation alerts

## ğŸ“ Ã–ÄŸrenim Ã‡Ä±ktÄ±larÄ±

Bu projeyi tamamladÄ±ktan sonra ÅŸunlarÄ± Ã¶ÄŸreneceksin:

### Teknik Skills
- âœ… Outlier detection algorithms (IF, LOF)
- âœ… Feature engineering for fraud detection
- âœ… Imbalanced learning techniques (SMOTE, cost-sensitive)
- âœ… Model evaluation for imbalanced problems
- âœ… Explainable AI (SHAP, LIME)
- âœ… MLOps pipeline (CI/CD, monitoring)

### Business Understanding
- âœ… Fraud detection domain knowledge
- âœ… Cost-benefit analysis
- âœ… Threshold optimization
- âœ… False positive vs false negative trade-offs
- âœ… Real-time vs batch processing decisions

### Production Skills
- âœ… Model deployment strategies
- âœ… Performance monitoring
- âœ… A/B testing for models
- âœ… Security considerations
- âœ… Scalability planning

## ğŸ¤ KatkÄ±da Bulunma

Bu eÄŸitim materyalini geliÅŸtirmek iÃ§in:
1. Issues aÃ§abilirsin
2. Pull request gÃ¶nderebilirsin  
3. Yeni dataset Ã¶nerileri yapabilirsin
4. Documentation iyileÅŸtirmeleri yapabilirsin

## ğŸ“š Ek Kaynaklar

### Fraud Detection
- [Fraud Detection Handbook](https://fraud-detection-handbook.github.io/fraud-detection-handbook/)
- [Imbalanced Learning](https://imbalanced-learn.org/)

### Explainable AI
- [SHAP Documentation](https://shap.readthedocs.io/)
- [LIME Tutorial](https://github.com/marcotcr/lime)

### MLOps
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [MLOps Best Practices](https://ml-ops.org/)

---

**ğŸ¯ Ready to start? Run `python run_demo.py` and begin your fraud detection journey!**
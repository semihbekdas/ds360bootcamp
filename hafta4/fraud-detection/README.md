# Hafta 4: Finans Sprinti - Fraud Detection ğŸ¦

## ğŸ“‹ Konu BaÅŸlÄ±klarÄ± ve Ã–ÄŸrenilecekler

### 1. ğŸ¯ Outlier Detection
- **Isolation Forest**: Anomaly detection iÃ§in ensemble method
- **Local Outlier Factor (LOF)**: Density-based outlier detection
- **KarÅŸÄ±laÅŸtÄ±rma**: Supervised vs Unsupervised yaklaÅŸÄ±mlar
- **Hyperparameter tuning**: contamination, n_neighbors optimizasyonu

### 2. ğŸ”§ Feature Scaling ve Encoding
- **Scaling Methods**: StandardScaler vs RobustScaler vs MinMaxScaler
- **Categorical Encoding**: OneHot vs Label vs Ordinal
- **Feature Engineering**: Log transformation, interaction features
- **Missing Value Handling**: Imputation strategies
- **Class Imbalance**: SMOTE, ADASYN, SMOTETomek

### 3. ğŸ“Š ROC-AUC ve PR-AUC Metrikleri
- **ROC-AUC**: True Positive Rate vs False Positive Rate
- **PR-AUC**: Precision vs Recall (imbalanced data iÃ§in kritik)
- **Threshold Optimization**: Business cost minimization
- **Confusion Matrix**: TP, FP, TN, FN analizi
- **Business Metrics**: Cost-benefit analysis

### 4. ğŸ” Model AÃ§Ä±klanabilirlik
- **SHAP (SHapley Additive exPlanations)**:
  - TreeExplainer: Tree-based modeller iÃ§in
  - KernelExplainer: Model-agnostic yaklaÅŸÄ±m
  - Feature importance ve dependence plots
- **LIME (Local Interpretable Model-agnostic Explanations)**:
  - Local aÃ§Ä±klamalar
  - Tabular explainer
- **Global vs Local aÃ§Ä±klamalar**
- **Fraud pattern analizi**

### 5. ğŸš€ CI/CD Pipeline ve Deployment
- **Data Validation**: Schema ve quality checks
- **Model Training**: Automated retraining
- **Performance Monitoring**: Drift detection
- **A/B Testing**: Model comparison
- **Production Deployment**: Staging â†’ Production
- **Security**: Model signing, access control

## ğŸ¯ KullanÄ±lan Dataset: Credit Card Fraud Detection

Bu proje **gerÃ§ek dÃ¼nya fraud detection** problemini simÃ¼le etmek iÃ§in en uygun dataset'i kullanÄ±r:

### Dataset Ã–zellikleri
- **Boyut**: 284,807 iÅŸlem
- **Imbalance**: %99.83 Normal, %0.17 Fraud (gerÃ§ekÃ§i oran)
- **Features**: 30 kolon
  - `V1-V28`: PCA ile dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ gizli features (privacy iÃ§in)
  - `Time`: Ä°ÅŸlem zamanÄ± (saniye cinsinden)
  - `Amount`: Ä°ÅŸlem tutarÄ±
  - `Class`: 0=Normal, 1=Fraud (target variable)

### Neden Bu Dataset?
- âœ… **GerÃ§ekÃ§i imbalance**: Production fraud rate'ini yansÄ±tÄ±r
- âœ… **Preprocessed**: PCA ile privacy korunmuÅŸ
- âœ… **TemizlenmiÅŸ**: Missing value yok
- âœ… **HÄ±zlÄ± training**: Makul boyut
- âœ… **EÄŸitim dostu**: TÃ¼m konular iÃ§in ideal

## ğŸ—ï¸ Proje YapÄ±sÄ±

```
hafta4/fraud-detection/
â”œâ”€â”€ src/                           # Ana kaynak kodlar
â”‚   â”œâ”€â”€ outlier_detection.py       # Isolation Forest & LOF
â”‚   â”œâ”€â”€ preprocessing.py           # Feature scaling & encoding
â”‚   â”œâ”€â”€ evaluation.py             # ROC-AUC, PR-AUC metrikleri
â”‚   â”œâ”€â”€ explainability_clean.py   # SHAP/LIME aÃ§Ä±klamalarÄ±
â”‚   â””â”€â”€ pipeline.py               # End-to-end pipeline
â”œâ”€â”€ tests/                         # Unit testler
â”‚   â””â”€â”€ test_pipeline.py          
â”œâ”€â”€ .github/workflows/             # CI/CD pipeline
â”‚   â””â”€â”€ ci_cd.yml                 # GitHub Actions
â”œâ”€â”€ config/                        # KonfigÃ¼rasyon dosyalarÄ±
â”‚   â””â”€â”€ config.yaml               # Model ve training parametreleri
â”œâ”€â”€ data/                          # Veri klasÃ¶rleri
â”‚   â”œâ”€â”€ raw/                      # Ham veri
â”‚   â””â”€â”€ processed/                # Ä°ÅŸlenmiÅŸ veri
â”œâ”€â”€ models/                        # EÄŸitilmiÅŸ modeller
â”œâ”€â”€ logs/                          # Log dosyalarÄ±
â”œâ”€â”€ notebooks/                     # Jupyter notebooks (analiz iÃ§in)
â”œâ”€â”€ download_data.py              # Dataset indirme utility
â”œâ”€â”€ run_demo.py                   # Interaktif demo
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # Bu dosya
```

## âš¡ï¸ HÄ±zlÄ± BaÅŸlangÄ±Ã§

```bash
# Proje klasÃ¶rÃ¼ne geÃ§
cd hafta4/fraud-detection

# Sanal ortam (Ã¶nerilir)
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# BaÄŸÄ±mlÄ±lÄ±klarÄ± kur
pip install -r requirements.txt
```

Pipeline varsayÄ±lan olarak synthetic fraud datasÄ± Ã¼retir. GerÃ§ek dataset kullanmak istersen KaggleHub ile indirme seÃ§eneÄŸi mevcut.

```bash
# VarsayÄ±lan: synthetic data, modeller kaydedilir
python src/pipeline.py --mode train --save_models

# Kaggle dataset'ini otomatik indirip eÄŸit
python src/pipeline.py --mode train --use_kagglehub --save_models

# Belirli bir CSV ile Ã§alÄ±ÅŸ
python src/pipeline.py --mode train --data data/raw/creditcard.csv --save_models
```

CLI modlarÄ±:
- `--mode train` (varsayÄ±lan): End-to-end pipeline, deÄŸerlendirme ve aÃ§Ä±klanabilirlik.
- `--mode predict`: KayÄ±tlÄ± modellerle hÄ±zlÄ± tahmin Ã§Ä±ktÄ±sÄ± gÃ¶sterir.
- `--mode explain`: SeÃ§ilen model iÃ§in SHAP/LIME Ã¶zetleri Ã¼retir.

`--load_models` bayraÄŸÄ± hazÄ±r modelleri `models/` klasÃ¶rÃ¼nden yÃ¼kler. Modeller yoksa pipeline otomatik yeniden eÄŸitir.

## ğŸ”§ Veri YÃ¶netimi

```bash
# Kaggle datasÄ±nÄ± helper script ile indir
python src/1_download_data.py

# Demo (synthetic data ile menÃ¼ tabanlÄ±)
python run_demo.py
```

Pipeline Ã§Ä±ktÄ±larÄ±:
- `models/` iÃ§inde `*_model.pkl`, `preprocessor.pkl`, `feature_info.pkl`
- `mlruns/` altÄ±nda MLflow metadata (varsayÄ±lan olarak yerel SQLite backend)
- `logs/` klasÃ¶rÃ¼ altÄ±nda `fraud_detection.log`

SHAP waterfall grafiÄŸi bazÄ± kombinasyonlarda `Explanation` nesnesi beklediÄŸi iÃ§in uyarÄ± verebilir; pipeline akÄ±ÅŸÄ± bu uyarÄ±yÄ± loglayÄ±p devam eder.

MLflow iÃ§in Ã¶zel bir sunucu belirtmediysen config fallback olarak `mlruns/mlflow.db` SQLite dosyasÄ±nÄ± kullanÄ±r. UI gÃ¶rmek iÃ§in:

```bash
mlflow ui --backend-store-uri sqlite:///mlruns/mlflow.db
```

## ğŸ® Demo ve Ã–rnekler

### 1. Ä°nteraktif Demo
```bash
python run_demo.py
```
**Menu seÃ§enekleri:**
- Preprocessing demo
- Outlier detection demo  
- Evaluation metrikleri
- Model aÃ§Ä±klanabilirlik
- Full pipeline

### 2. Outlier Detection
```python
from src.outlier_detection import OutlierDetector

# Isolation Forest
detector = OutlierDetector(contamination=0.002)  # %0.2 fraud oranÄ±
detector.fit_isolation_forest(X_train_processed.values)
labels, scores = detector.predict_isolation_forest(X_test_processed.values)

# Performance evaluation
metrics = detector.evaluate_performance(y_test_processed, scores)
print(metrics)
```

### 3. Feature Preprocessing
```python
from src.preprocessing import FeaturePreprocessor, ImbalanceHandler

# Preprocessing
preprocessor = FeaturePreprocessor(
    scaling_method='robust',  # Outlier'lara dayanÄ±klÄ±
    encoding_method='onehot'
)
processed = preprocessor.fit_transform(train_df, target_col='target')
X_train_processed = processed.drop('target', axis=1)
y_train_processed = processed['target']

# Imbalance handling
X_balanced, y_balanced = ImbalanceHandler.apply_smote(X_train_processed, y_train_processed)
```

### 4. Model Evaluation
```python
from src.evaluation import FraudEvaluator

evaluator = FraudEvaluator(model, "Random Forest")
results = evaluator.evaluate_binary_classification(X_test_processed, y_test_processed)
fpr, tpr, roc_thresholds = evaluator.roc_curve_points()
precision, recall, pr_thresholds = evaluator.precision_recall_points()
```

### 5. Model AÃ§Ä±klanabilirlik
```python
import numpy as np
from src.explainability_clean import ModelExplainer

explainer = ModelExplainer(
  model,
  X_balanced,
  feature_names=list(X_train_processed.columns),
  class_names=['Normal', 'Fraud'],
  y_train=y_balanced,
)

X_sample = X_test_processed.head(100)
if explainer.initialize_shap('tree'):
  shap_values, X_sample = explainer.compute_shap_values(X_sample)
  if shap_values is not None:
    explainer.plot_shap_summary(X_sample)
    explainer.plot_shap_waterfall(X_sample, index=0)

importance = explainer.global_feature_importance(X_sample, y_test_processed[:len(X_sample)])
fraud_patterns = explainer.analyze_fraud_patterns(np.asarray(X_sample), y_test_processed[:len(X_sample)])
```

## âœ… Testler

Pipeline deÄŸiÅŸikliklerini kontrol etmek iÃ§in unit testler mevcut. `pytest` varsayÄ±lan gereksinim listesinde deÄŸildir; manuel kurulumdan sonra testleri Ã§alÄ±ÅŸtÄ±rabilirsin.

```bash
pip install pytest
python -m pytest tests/test_simple.py tests/test_pipeline.py
```

Testler SMOTE ve SHAP gibi bileÅŸenleri kullandÄ±ÄŸÄ± iÃ§in ilk Ã§alÄ±ÅŸtÄ±rmada modellerin veya preprocess dosyalarÄ±nÄ±n oluÅŸturulmuÅŸ olmasÄ± gerekir (`python src/pipeline.py --mode train --save_models`).

## ğŸ“Š Beklenen SonuÃ§lar ve Ã–ÄŸrenim Hedefleri

### 1. Outlier Detection Performance
- **Isolation Forest**: ROC-AUC ~0.85-0.90
- **LOF**: ROC-AUC ~0.80-0.85
- **Hybrid approach**: Ensemble of methods

### 2. Supervised Learning Benchmarks
- **Random Forest**: ROC-AUC ~0.95+, PR-AUC ~0.75+
- **Logistic Regression**: ROC-AUC ~0.93+, PR-AUC ~0.65+
- **Gradient Boosting**: ROC-AUC ~0.96+, PR-AUC ~0.80+

### 3. Feature Importance Insights
- **Time patterns**: Gece fraud'larÄ± daha yÃ¼ksek
- **Amount patterns**: KÃ¼Ã§Ã¼k ve Ã§ok bÃ¼yÃ¼k miktarlar risky
- **PCA features**: V4, V11, V12 genellikle Ã¶nemli

### 4. Business Metrics
- **Optimal threshold**: ~0.3-0.4 (cost minimization iÃ§in)
- **Cost reduction**: %60-80 compared to random checking
- **False positive rate**: <%5 (customer experience iÃ§in)

## ğŸ¯ Learning Path ve Exercises

### BaÅŸlangÄ±Ã§ Seviyesi
1. **Dataset exploration**: EDA ve basic statistics
2. **Simple outlier detection**: Isolation Forest ile baÅŸla
3. **Basic preprocessing**: Scaling ve encoding
4. **Model training**: Single algorithm (Random Forest)
5. **Basic evaluation**: ROC-AUC ve confusion matrix

### Orta Seviye
1. **Multiple outlier methods**: IF + LOF karÅŸÄ±laÅŸtÄ±rmasÄ±
2. **Advanced preprocessing**: Feature engineering
3. **Imbalance handling**: SMOTE ile class balancing
4. **Threshold optimization**: Business cost minimization
5. **Model comparison**: Multiple algorithms

### Ä°leri Seviye
1. **Ensemble methods**: Multiple outlier detector fusion
2. **Custom preprocessing pipeline**: Domain-specific features
3. **Advanced evaluation**: PR-AUC focus, cost-sensitive metrics
4. **Model explainability**: SHAP + LIME comprehensive analysis
5. **Production pipeline**: CI/CD ile automated deployment

### Expert Seviye
1. **Real-time detection**: Streaming data processing
2. **Model drift detection**: Performance monitoring
3. **A/B testing**: Model comparison in production
4. **Custom explainability**: Domain-specific explanations
5. **End-to-end MLOps**: Complete production system

## ğŸ”¥ Advanced Features

### 1. Hyperparameter Optimization
```python
# Grid search for optimal parameters
from sklearn.model_selection import GridSearchCV

param_grid = {
    'contamination': [0.001, 0.002, 0.005],
    'n_estimators': [50, 100, 200]
}
```

### 2. Ensemble Methods
```python
# Combine multiple outlier detectors
ensemble_prediction = (if_pred + lof_pred + svm_pred) / 3
```

### 3. Real-time Scoring
```python
# Fast inference pipeline
@app.route('/predict', methods=['POST'])
def predict_fraud():
    features = preprocess(request.json)
    prediction = model.predict_proba(features)[0][1]
    return {'fraud_probability': prediction}
```

### 4. Model Monitoring
```python
# Performance drift detection
def detect_drift(model, X_new, threshold=0.1):
    current_auc = roc_auc_score(y_true, model.predict_proba(X_new)[:, 1])
    return abs(baseline_auc - current_auc) > threshold
```

## ğŸš€ Production Deployment

### 1. CI/CD Pipeline
```yaml
# .github/workflows/ci_cd.yml
- Data validation
- Model training  
- Performance testing
- Security scanning
- Staging deployment
- Production deployment
- Monitoring setup
```

### 2. Model Serving
```python
# FastAPI ile REST API
from fastapi import FastAPI
app = FastAPI()

@app.post("/predict")
async def predict_transaction(transaction: TransactionModel):
    # Preprocessing + Prediction + Logging
    return PredictionResponse(is_fraud=prediction, confidence=confidence)
```

### 3. Monitoring Dashboard
- **Performance metrics**: ROC-AUC, PR-AUC trends
- **Business metrics**: False positive rate, cost savings
- **Data drift**: Feature distribution changes
- **Model drift**: Performance degradation alerts

## ğŸ“ Ã–ÄŸrenim Ã‡Ä±ktÄ±larÄ±

Bu projeyi tamamladÄ±ktan sonra ÅŸunlarÄ± Ã¶ÄŸreneceksin:

### Teknik Skills
- âœ… Outlier detection algorithms (IF, LOF)
- âœ… Feature engineering for fraud detection
- âœ… Imbalanced learning techniques (SMOTE, cost-sensitive)
- âœ… Model evaluation for imbalanced problems
- âœ… Explainable AI (SHAP, LIME)
- âœ… MLOps pipeline (CI/CD, monitoring)

### Business Understanding
- âœ… Fraud detection domain knowledge
- âœ… Cost-benefit analysis
- âœ… Threshold optimization
- âœ… False positive vs false negative trade-offs
- âœ… Real-time vs batch processing decisions

### Production Skills
- âœ… Model deployment strategies
- âœ… Performance monitoring
- âœ… A/B testing for models
- âœ… Security considerations
- âœ… Scalability planning

## ğŸ¤ KatkÄ±da Bulunma

Bu eÄŸitim materyalini geliÅŸtirmek iÃ§in:
1. Issues aÃ§abilirsin
2. Pull request gÃ¶nderebilirsin  
3. Yeni dataset Ã¶nerileri yapabilirsin
4. Documentation iyileÅŸtirmeleri yapabilirsin

## ğŸ“š Ek Kaynaklar

### Fraud Detection
- [Fraud Detection Handbook](https://fraud-detection-handbook.github.io/fraud-detection-handbook/)
- [Imbalanced Learning](https://imbalanced-learn.org/)

### Explainable AI
- [SHAP Documentation](https://shap.readthedocs.io/)
- [LIME Tutorial](https://github.com/marcotcr/lime)

### MLOps
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [MLOps Best Practices](https://ml-ops.org/)

---

**ğŸ¯ Ready to start? Run `python run_demo.py` and begin your fraud detection journey!**
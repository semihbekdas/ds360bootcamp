"""
ModÃ¼l 1 â€” Outlier Detection (RAW / scale yok)
Kaynak (HAM CSV): /Users/yaseminarslan/Desktop/ds360_ikincihafta/hafta4/fraud-detection/data/raw/creditcard_fraud.csv
Ã‡Ä±ktÄ±lar:
  - ./data/processed/dataset_with_anomaly_scores_raw.csv
  - ./data/processed/outlier_meta_raw.json
Not: HiÃ§bir Ã¶lÃ§ekleme/encoding yok. IF & LOF ham deÄŸerlerle Ã§alÄ±ÅŸÄ±r.
"""

from pathlib import Path
import os, json
import numpy as np
import pandas as pd

from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve

DATA_DIR = Path("./data/processed"); DATA_DIR.mkdir(parents=True, exist_ok=True)

# >>>>> HAM VERÄ° YOLU (senin verdiÄŸin yol) <<<<<
RAW_PATH = Path("/Users/yaseminarslan/Desktop/ds360_ikincihafta/hafta4/fraud-detection/data/raw/creditcard_fraud.csv")

OUT_CSV  = DATA_DIR / "dataset_with_anomaly_scores_raw.csv"
OUT_META = DATA_DIR / "outlier_meta_raw.json"

def choose_threshold_by_f1(y_true, scores):
    prec, rec, thr = precision_recall_curve(y_true, scores)
    f1 = 2 * (prec * rec) / (prec + rec + 1e-9)
    best_idx = int(np.argmax(f1))
    thr_choice = float(thr[max(0, min(best_idx-1, len(thr)-1))]) if len(thr) > 0 else 0.0
    return {"threshold": thr_choice, "precision": float(prec[best_idx]),
            "recall": float(rec[best_idx]), "f1": float(f1[best_idx])}

def main():
    assert RAW_PATH.exists(), f"Ham veri bulunamadÄ±: {RAW_PATH}"
    df = pd.read_csv(RAW_PATH)
    assert "Class" in df.columns, "Hedef kolon 'Class' bulunamadÄ±."

    # split yoksa oluÅŸtur (stratified)
    if "split" not in df.columns:
        y_tmp = df["Class"].astype(int).values
        idx_train, idx_test = train_test_split(
            np.arange(len(df)), test_size=0.30, random_state=42, stratify=y_tmp
        )
        split = np.array(["train"]*len(df), dtype=object); split[idx_test] = "test"
        df["split"] = split

    feature_cols = [c for c in df.columns if c not in ("Class","split")]
    train = df[df["split"]=="train"].reset_index(drop=True)
    test  = df[df["split"]=="test"].reset_index(drop=True)

    X_train = train[feature_cols].values
    X_test  = test[feature_cols].values
    y_test  = test["Class"].astype(int).values

    print(f"[OK] Kaynak: {RAW_PATH}")
    print(f"[OK] Train: {X_train.shape} | Test: {X_test.shape} | Test fraud oranÄ±: {y_test.mean():.6f}")

    # --- Isolation Forest (ham) ---
    iso = IsolationForest(n_estimators=200, contamination="auto", random_state=42, n_jobs=-1)
    iso.fit(X_train)
    if_scores_train = -iso.decision_function(X_train)  # yÃ¼ksek = anomali
    if_scores_test  = -iso.decision_function(X_test)

    if_thr = choose_threshold_by_f1(y_test, if_scores_test)
    if_alarm_test = (if_scores_test >= if_thr["threshold"]).astype(int)

    if_roc = float(roc_auc_score(y_test, if_scores_test))
    if_ap  = float(average_precision_score(y_test, if_scores_test))
    print(f"[IF] ROC-AUC={if_roc:.4f} | PR-AUC(AP)={if_ap:.4f} | "
          f"EÅŸikâ‰ˆ{if_thr['threshold']:.6f} | P={if_thr['precision']:.3f} R={if_thr['recall']:.3f} F1={if_thr['f1']:.3f} "
          f"| Alarm oranÄ±={if_alarm_test.mean():.4f}")

    # --- LOF (novelty=True, ham) ---
    lof = LocalOutlierFactor(n_neighbors=35, contamination="auto", novelty=True)
    lof.fit(X_train)
    lof_scores_train = -lof.score_samples(X_train)     # yÃ¼ksek = anomali
    lof_scores_test  = -lof.score_samples(X_test)

    lof_thr = choose_threshold_by_f1(y_test, lof_scores_test)
    lof_alarm_test = (lof_scores_test >= lof_thr["threshold"]).astype(int)

    lof_roc = float(roc_auc_score(y_test, lof_scores_test))
    lof_ap  = float(average_precision_score(y_test, lof_scores_test))
    print(f"[LOF] ROC-AUC={lof_roc:.4f} | PR-AUC(AP)={lof_ap:.4f} | "
          f"EÅŸikâ‰ˆ{lof_thr['threshold']:.6f} | P={lof_thr['precision']:.3f} R={lof_thr['recall']:.3f} F1={lof_thr['f1']:.3f} "
          f"| Alarm oranÄ±={lof_alarm_test.mean():.4f}")

    # --- Skor/Alarm kolonlarÄ±nÄ± yaz ---
    df_out = df.copy()
    df_out["if_score"]  = np.nan; df_out["lof_score"] = np.nan
    df_out.loc[df_out["split"]=="train","if_score"]  = if_scores_train
    df_out.loc[df_out["split"]=="train","lof_score"] = lof_scores_train
    df_out.loc[df_out["split"]=="test","if_score"]   = if_scores_test
    df_out.loc[df_out["split"]=="test","lof_score"]  = lof_scores_test

    df_out["if_alarm"]  = 0; df_out["lof_alarm"] = 0
    df_out.loc[df_out["split"]=="test","if_alarm"]  = if_alarm_test
    df_out.loc[df_out["split"]=="test","lof_alarm"] = lof_alarm_test

    df_out.to_csv(OUT_CSV, index=False)
    print(f"[OK] Kaydedildi â†’ {OUT_CSV}")

    meta = {
        "input_file": str(RAW_PATH),
        "output_file": str(OUT_CSV),
        "n_train": int(len(train)), "n_test": int(len(test)),
        "iforest": {"roc_auc": if_roc, "pr_auc_ap": if_ap, **if_thr},
        "lof":     {"roc_auc": lof_roc, "pr_auc_ap": lof_ap, **lof_thr, "n_neighbors": 35},
        "notes": [
            "Ã–lÃ§ekleme yok; skor yÃ¶nleri normalize: yÃ¼ksek skor = daha anomali.",
            "EÅŸikler PR eÄŸrisinde F1â€™i maksimize eden noktadan seÃ§ildi.",
            "Skorlar train+test iÃ§in Ã¼retildi; testte alarm etiketleri yazÄ±ldÄ±."
        ]
    }
    with open(OUT_META, "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)
    print(f"[OK] Meta kayÄ±t â†’ {OUT_META}")

if __name__ == "__main__":
    main()


#[IF] ROC-AUC=0.9480 | PR-AUC(AP)=0.1381 | EÅŸikâ‰ˆ0.148798 | P=0.253 R=0.270 F1=0.261 | Alarm oranÄ±=0.0019
'''
ğŸ”¹ **[IF]**
Bu sonuÃ§lar **Isolation Forest (IF)** modeli iÃ§in.

---

ğŸ”¹ **ROC-AUC = 0.9480**

* ROC-AUC, modelin **normal vs fraud ayÄ±rt etme becerisini** Ã¶lÃ§er.
* 1â€™e ne kadar yakÄ±nsa, o kadar iyi ayÄ±rt ediyor demektir.
* 0.948 â‰ˆ **Ã§ok yÃ¼ksek** â†’ IF, skor Ã¼retmede gayet iyi.

---

ğŸ”¹ **PR-AUC (AP) = 0.1381**

* PR-AUC, â€œPrecision-Recall eÄŸrisi altÄ±ndaki alan.â€
* Fraud Ã§ok az olduÄŸu iÃ§in **PR-AUC daha Ã¶nemlidir**.
* 0.1381 â†’ dÃ¼ÅŸÃ¼k sayÄ±lÄ±r. Ã‡Ã¼nkÃ¼ dengesiz veri setinde (fraud %0.17) precision-recall iÅŸleri zor.
* Yani ROC iyi ama fraud yakalamada pratikte o kadar da ÅŸahane deÄŸil.

---

ğŸ”¹ **EÅŸik â‰ˆ 0.148798**

* Isolation Forest her iÅŸleme bir **â€œanomaly scoreâ€** veriyor.
* Skor â†‘ â†’ daha anormal (fraud olasÄ±lÄ±ÄŸÄ± daha fazla).
* Biz bir noktada â€œÅŸuradan sonrasÄ± fraud olsunâ€ diye eÅŸik koyuyoruz.
* Bu eÅŸik **F1 skorunu en Ã§ok artÄ±ran nokta**.

---

ğŸ”¹ **P = 0.253 (Precision)**

* â€œModel fraud dediÄŸinde, %25â€™i gerÃ§ekten fraud.â€
* Yani alarm verdiÄŸi her 4 iÅŸlemin 3â€™Ã¼ aslÄ±nda normal â†’ **Ã§ok false alarm** var.

---

ğŸ”¹ **R = 0.270 (Recall)**

* â€œGerÃ§ek fraudâ€™larÄ±n %27â€™sini yakaladÄ±.â€
* Yani fraudâ€™larÄ±n bÃ¼yÃ¼k kÄ±smÄ±nÄ± kaÃ§Ä±rÄ±yor.

---

ğŸ”¹ **F1 = 0.261**

* Precision ve Recallâ€™un dengesi.
* 0.26 dÃ¼ÅŸÃ¼k â†’ model bu eÅŸikte hem Ã§ok alarm veriyor hem de Ã§oÄŸunu kaÃ§Ä±rÄ±yor.

---

ğŸ”¹ **Alarm oranÄ± = 0.0019**

* TÃ¼m iÅŸlemlerin sadece %0.19â€™u fraud alarmÄ± aldÄ±.
* Veri setinde fraud %0.17 civarÄ±nda â†’ model azÄ±cÄ±k fazla alarm veriyor.

---

ğŸ“Œ **Ã–zet:**

* Isolation Forest gÃ¼zel anomaly score Ã¼retiyor (ROC yÃ¼ksek).
* Ama doÄŸrudan alarm mekanizmasÄ± (threshold ile etiketleme) Ã§ok baÅŸarÄ±lÄ± deÄŸil â†’ Precision/Recall dÃ¼ÅŸÃ¼k.
* Bu yÃ¼zden **en iyi kullanÄ±m ÅŸekli**, `if_score`â€™u **ek bir feature** olarak supervised modele sokmak.
* BÃ¶ylece Logistic Regression, XGBoost gibi modeller `if_score` + diÄŸer deÄŸiÅŸkenleri birlikte kullanÄ±p daha iyi Precision/Recall dengesine ulaÅŸÄ±r.

---

'''
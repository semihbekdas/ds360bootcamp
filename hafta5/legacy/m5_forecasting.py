#!/usr/bin/env python3
"""
M5 Forecasting - Zaman Serisi Talep Tahmini
EÄŸitim AmaÃ§lÄ± Kod - Basit ve AnlaÅŸÄ±lÄ±r Implementasyon

Bu script M5 Competition verisi ile talep tahmini yapar.
KÃ¼Ã§Ã¼k bir alt-kÃ¼me ile Ã§alÄ±ÅŸarak hÄ±zlÄ± sonuÃ§ alÄ±nmasÄ±nÄ± saÄŸlar.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
import os
import pickle
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any

# Scikit-learn
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.preprocessing import LabelEncoder

# Zaman serisi kÃ¼tÃ¼phaneleri
import statsmodels.api as sm
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import ExponentialSmoothing

# Prophet iÃ§in try/except
try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    print("Prophet kÃ¼tÃ¼phanesi bulunamadÄ±. Prophet modelleri atlanacak.")
    PROPHET_AVAILABLE = False

# LightGBM iÃ§in try/except
try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    print("LightGBM kÃ¼tÃ¼phanesi bulunamadÄ±. LightGBM modelleri atlanacak.")
    LIGHTGBM_AVAILABLE = False

# Prefect iÃ§in try/except (isteÄŸe baÄŸlÄ±)
try:
    from prefect import task, flow
    PREFECT_AVAILABLE = True
except ImportError:
    print("Prefect kÃ¼tÃ¼phanesi bulunamadÄ±. Normal fonksiyonlar kullanÄ±lacak.")
    PREFECT_AVAILABLE = False

warnings.filterwarnings('ignore')

# KonfigÃ¼rasyon
CONFIG = {
    'data_path': './data/',
    'artifacts_path': './artifacts/',
    'state_id': 'CA',  # Sadece California
    'store_id': 'CA_1',  # Tek maÄŸaza
    'n_items': 10,  # Sadece 10 Ã¼rÃ¼n
    'train_days': 365 * 2,  # Son 2 yÄ±l
    'forecast_horizon': 28,  # 28 gÃ¼n tahmin
    'random_seed': 42
}

class M5Forecaster:
    """
    M5 Forecasting ana sÄ±nÄ±fÄ±
    
    Bu sÄ±nÄ±f veri yÃ¼kleme, preprocessing, modelleme ve deÄŸerlendirme
    iÅŸlemlerini organize eder.
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.data = {}
        self.models = {}
        self.predictions = {}
        self.metrics = {}
        
        # Ã‡Ä±ktÄ± klasÃ¶rlerini oluÅŸtur
        os.makedirs(config['artifacts_path'], exist_ok=True)
        
        print(f"M5 Forecaster baÅŸlatÄ±ldÄ±")
        print(f"Hedef: {config['state_id']} eyaleti, {config['store_id']} maÄŸazasÄ±")
        print(f"ÃœrÃ¼n sayÄ±sÄ±: {config['n_items']}")
    
    def load_data(self) -> None:
        """
        M5 verilerini yÃ¼kle ve temizle
        
        M5 Competition verisi 3 ana dosyadan oluÅŸur:
        - sales_train_validation.csv: SatÄ±ÅŸ verileri
        - calendar.csv: Tarih bilgileri
        - sell_prices.csv: Fiyat bilgileri (opsiyonel)
        """
        try:
            print("\n=== VERÄ° YÃœKLEME ===")
            
            # 1. SatÄ±ÅŸ verilerini yÃ¼kle
            print("SatÄ±ÅŸ verileri yÃ¼kleniyor...")
            sales_path = os.path.join(self.config['data_path'], 'sales_train_validation.csv')
            
            if not os.path.exists(sales_path):
                raise FileNotFoundError(f"SatÄ±ÅŸ verisi bulunamadÄ±: {sales_path}")
            
            # Sadece belirtilen eyalet ve maÄŸazayÄ± filtrele
            sales_df = pd.read_csv(sales_path)
            print(f"Toplam veri boyutu: {sales_df.shape}")
            
            # Filtreleme
            mask = (sales_df['state_id'] == self.config['state_id']) & \
                   (sales_df['store_id'] == self.config['store_id'])
            
            sales_filtered = sales_df[mask].head(self.config['n_items'])
            print(f"FiltrelenmiÅŸ veri boyutu: {sales_filtered.shape}")
            
            # 2. Takvim verilerini yÃ¼kle
            print("Takvim verileri yÃ¼kleniyor...")
            calendar_path = os.path.join(self.config['data_path'], 'calendar.csv')
            
            if not os.path.exists(calendar_path):
                raise FileNotFoundError(f"Takvim verisi bulunamadÄ±: {calendar_path}")
            
            calendar_df = pd.read_csv(calendar_path)
            calendar_df['date'] = pd.to_datetime(calendar_df['date'])
            
            # 3. Verileri birleÅŸtir
            print("Veriler birleÅŸtiriliyor...")
            long_data = self._reshape_to_long_format(sales_filtered, calendar_df)
            
            self.data['sales'] = sales_filtered
            self.data['calendar'] = calendar_df
            self.data['long'] = long_data
            
            print(f"âœ“ Veri yÃ¼kleme tamamlandÄ±. Toplam satÄ±r: {len(long_data)}")
            
        except Exception as e:
            print(f"âŒ Veri yÃ¼kleme hatasÄ±: {e}")
            raise
    
    def _reshape_to_long_format(self, sales_df: pd.DataFrame, calendar_df: pd.DataFrame) -> pd.DataFrame:
        """
        SatÄ±ÅŸ verisini geniÅŸ formattan uzun formata Ã§evir
        
        M5 verisi geniÅŸ formatta (her gÃ¼n bir sÃ¼tun). Zaman serisi analizi
        iÃ§in uzun format gerekli (her satÄ±r bir gÃ¼n-Ã¼rÃ¼n kombinasyonu).
        """
        print("Veri formatÄ± uzun formata Ã§evriliyor...")
        
        # ID sÃ¼tunlarÄ±nÄ± al
        id_cols = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']
        
        # SatÄ±ÅŸ sÃ¼tunlarÄ±nÄ± al (d_1, d_2, ... formatÄ±nda)
        sales_cols = [col for col in sales_df.columns if col.startswith('d_')]
        
        # Uzun formata Ã§evir
        long_df = pd.melt(
            sales_df[id_cols + sales_cols],
            id_vars=id_cols,
            value_vars=sales_cols,
            var_name='d',
            value_name='sales'
        )
        
        # Takvim verisi ile birleÅŸtir
        long_df = long_df.merge(calendar_df[['d', 'date', 'wm_yr_wk', 'weekday', 'month', 'year']], on='d')
        long_df = long_df.sort_values(['id', 'date']).reset_index(drop=True)
        
        # NaN deÄŸerleri 0 ile doldur
        long_df['sales'] = long_df['sales'].fillna(0)
        
        print(f"âœ“ Format dÃ¶nÃ¼ÅŸÃ¼mÃ¼ tamamlandÄ±. Åekil: {long_df.shape}")
        return long_df
    
    def prepare_time_series(self) -> None:
        """
        Zaman serisi verilerini hazÄ±rla ve bÃ¶l
        
        Burada time-based split yapÄ±yoruz. Shuffle yapmÄ±yoruz Ã§Ã¼nkÃ¼
        zaman serisi verilerinde sÄ±ra Ã¶nemli.
        """
        print("\n=== ZAMAN SERÄ°SÄ° HAZIRLIÄI ===")
        
        # Son N gÃ¼nÃ¼ al (daha hÄ±zlÄ± Ã§alÄ±ÅŸmasÄ± iÃ§in)
        long_df = self.data['long'].copy()
        
        # Tarih sÄ±ralamasÄ±
        long_df = long_df.sort_values('date')
        unique_dates = sorted(long_df['date'].unique())
        
        # Son train_days gÃ¼n al
        if len(unique_dates) > self.config['train_days']:
            start_date = unique_dates[-self.config['train_days']]
            long_df = long_df[long_df['date'] >= start_date]
            print(f"Son {self.config['train_days']} gÃ¼n kullanÄ±lÄ±yor: {start_date} - {unique_dates[-1]}")
        
        # Time-based split
        unique_dates = sorted(long_df['date'].unique())
        split_idx = len(unique_dates) - self.config['forecast_horizon']
        
        if split_idx <= 0:
            raise ValueError("Yeterli veri yok. Daha az forecast_horizon veya daha fazla veri gerekli.")
        
        train_end_date = unique_dates[split_idx - 1]
        test_start_date = unique_dates[split_idx]
        
        # Train/test ayÄ±rma
        train_df = long_df[long_df['date'] <= train_end_date]
        test_df = long_df[long_df['date'] >= test_start_date]
        
        print(f"Train dÃ¶nemi: {train_df['date'].min()} - {train_df['date'].max()}")
        print(f"Test dÃ¶nemi: {test_df['date'].min()} - {test_df['date'].max()}")
        print(f"Train boyutu: {len(train_df)}, Test boyutu: {len(test_df)}")
        
        self.data['train'] = train_df
        self.data['test'] = test_df
        
        # Her Ã¼rÃ¼n iÃ§in ayrÄ± zaman serisi oluÅŸtur
        self.data['item_series'] = {}
        for item_id in train_df['item_id'].unique():
            item_train = train_df[train_df['item_id'] == item_id].copy()
            item_test = test_df[test_df['item_id'] == item_id].copy()
            
            # Eksik gÃ¼nleri doldur (bazÄ± gÃ¼nler satÄ±ÅŸ olmayabilir)
            date_range = pd.date_range(start=item_train['date'].min(), 
                                     end=item_test['date'].max(), 
                                     freq='D')
            
            full_series = pd.DataFrame({'date': date_range})
            
            # Train ve test verilerini birleÅŸtir
            all_item_data = pd.concat([item_train, item_test])
            full_series = full_series.merge(all_item_data, on='date', how='left')
            full_series['sales'] = full_series['sales'].fillna(0)
            full_series['item_id'] = full_series['item_id'].fillna(item_id)
            
            # Train/test ayrÄ±mÄ±nÄ± tekrar yap
            train_mask = full_series['date'] <= train_end_date
            
            self.data['item_series'][item_id] = {
                'train': full_series[train_mask].copy(),
                'test': full_series[~train_mask].copy(),
                'full': full_series.copy()
            }
        
        print(f"âœ“ {len(self.data['item_series'])} Ã¼rÃ¼n iÃ§in zaman serisi hazÄ±rlandÄ±")
    
    def calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:
        """
        Tahmin performans metriklerini hesapla
        
        MAE: Mean Absolute Error
        RMSE: Root Mean Square Error  
        MAPE: Mean Absolute Percentage Error
        sMAPE: Symmetric Mean Absolute Percentage Error
        """
        # Negatif deÄŸerleri 0 yap
        y_pred = np.maximum(y_pred, 0)
        
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        
        # MAPE hesapla (sÄ±fÄ±r deÄŸerler iÃ§in korumalÄ±)
        mask = y_true != 0
        if mask.sum() > 0:
            mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100
        else:
            mape = float('inf')
        
        # sMAPE hesapla
        denominator = (np.abs(y_true) + np.abs(y_pred)) / 2
        mask = denominator != 0
        if mask.sum() > 0:
            smape = np.mean(np.abs(y_true[mask] - y_pred[mask]) / denominator[mask]) * 100
        else:
            smape = float('inf')
        
        return {
            'MAE': mae,
            'RMSE': rmse,
            'MAPE': mape,
            'sMAPE': smape
        }
    
    def train_naive_models(self) -> None:
        """
        Basit (naive) modelleri eÄŸit
        
        Bu modeller karmaÅŸÄ±k deÄŸil ama genellikle iyi baseline saÄŸlar:
        1. Naive: Son deÄŸeri tekrarla
        2. Seasonal Naive: GeÃ§en haftanÄ±n aynÄ± gÃ¼nÃ¼nÃ¼ tekrarla
        3. Moving Average: Hareketli ortalama
        """
        print("\n=== NAÄ°VE MODELLER ===")
        
        for item_id in self.data['item_series'].keys():
            print(f"ÃœrÃ¼n: {item_id}")
            
            train_series = self.data['item_series'][item_id]['train']
            test_length = len(self.data['item_series'][item_id]['test'])
            
            if len(train_series) == 0:
                print(f"âš ï¸  {item_id} iÃ§in yeterli train verisi yok")
                continue
                
            sales_values = train_series['sales'].values
            
            # 1. Naive Forecast (son deÄŸeri tekrarla)
            naive_pred = np.full(test_length, sales_values[-1])
            
            # 2. Seasonal Naive (7 gÃ¼n Ã¶nceyi tekrarla)
            seasonal_naive_pred = []
            for i in range(test_length):
                lookback_idx = len(sales_values) - 7 + (i % 7)
                if lookback_idx >= 0:
                    seasonal_naive_pred.append(sales_values[lookback_idx])
                else:
                    seasonal_naive_pred.append(sales_values[-1])
            seasonal_naive_pred = np.array(seasonal_naive_pred)
            
            # 3. Moving Average (son 7 gÃ¼nÃ¼n ortalamasÄ±)
            ma_window = min(7, len(sales_values))
            ma_value = np.mean(sales_values[-ma_window:])
            ma_pred = np.full(test_length, ma_value)
            
            # Tahminleri kaydet
            if item_id not in self.predictions:
                self.predictions[item_id] = {}
            
            self.predictions[item_id]['naive'] = naive_pred
            self.predictions[item_id]['seasonal_naive'] = seasonal_naive_pred
            self.predictions[item_id]['moving_average'] = ma_pred
        
        print("âœ“ Naive modeller tamamlandÄ±")
    
    def train_exponential_smoothing(self) -> None:
        """
        Exponential Smoothing modelleri eÄŸit
        
        Holt-Winters yÃ¶ntemi trend ve mevsimselliÄŸi yakalayabilir.
        """
        print("\n=== EXPONENTIAL SMOOTHING ===")
        
        for item_id in self.data['item_series'].keys():
            print(f"ÃœrÃ¼n: {item_id}")
            
            try:
                train_series = self.data['item_series'][item_id]['train']
                test_length = len(self.data['item_series'][item_id]['test'])
                
                if len(train_series) < 14:  # En az 2 hafta veri gerekli
                    print(f"âš ï¸  {item_id} iÃ§in yeterli veri yok (en az 14 gÃ¼n gerekli)")
                    continue
                
                sales_values = train_series['sales'].values
                
                # Holt-Winters modeli (trend + seasonality)
                # seasonal_periods=7 (haftalÄ±k mevsimsellik)
                model = ExponentialSmoothing(
                    sales_values,
                    trend='add',
                    seasonal='add',
                    seasonal_periods=7
                )
                
                fitted_model = model.fit()
                pred = fitted_model.forecast(steps=test_length)
                
                # Negatif deÄŸerleri 0 yap
                pred = np.maximum(pred, 0)
                
                if item_id not in self.predictions:
                    self.predictions[item_id] = {}
                
                self.predictions[item_id]['exponential_smoothing'] = pred
                
                # Modeli kaydet
                if item_id not in self.models:
                    self.models[item_id] = {}
                self.models[item_id]['exponential_smoothing'] = fitted_model
                
            except Exception as e:
                print(f"âš ï¸  {item_id} iÃ§in Exponential Smoothing hatasÄ±: {e}")
        
        print("âœ“ Exponential Smoothing tamamlandÄ±")
    
    def train_prophet_models(self) -> None:
        """
        Facebook Prophet modelleri eÄŸit
        
        Prophet Ã¶zellikle trend ve mevsimsellik olan zaman serilerinde baÅŸarÄ±lÄ±.
        """
        if not PROPHET_AVAILABLE:
            print("Prophet mevcut deÄŸil, atlanÄ±yor...")
            return
            
        print("\n=== PROPHET MODELS ===")
        
        for item_id in self.data['item_series'].keys():
            print(f"ÃœrÃ¼n: {item_id}")
            
            try:
                train_series = self.data['item_series'][item_id]['train']
                test_length = len(self.data['item_series'][item_id]['test'])
                
                if len(train_series) < 30:  # Prophet iÃ§in daha fazla veri gerekli
                    print(f"âš ï¸  {item_id} iÃ§in yeterli veri yok (en az 30 gÃ¼n gerekli)")
                    continue
                
                # Prophet formatÄ±na Ã§evir (ds: tarih, y: deÄŸer)
                prophet_df = pd.DataFrame({
                    'ds': train_series['date'],
                    'y': train_series['sales']
                })
                
                # Prophet modeli
                model = Prophet(
                    yearly_seasonality=False,  # KÄ±sa veri iÃ§in gerekli deÄŸil
                    weekly_seasonality=True,
                    daily_seasonality=False,
                    changepoint_prior_scale=0.1  # Daha yumuÅŸak trend deÄŸiÅŸimleri
                )
                
                model.fit(prophet_df)
                
                # Gelecek tarihleri oluÅŸtur
                future = model.make_future_dataframe(periods=test_length)
                forecast = model.predict(future)
                
                # Sadece tahmin kÄ±smÄ±nÄ± al
                pred = forecast['yhat'].iloc[-test_length:].values
                pred = np.maximum(pred, 0)  # Negatif deÄŸerleri 0 yap
                
                if item_id not in self.predictions:
                    self.predictions[item_id] = {}
                
                self.predictions[item_id]['prophet'] = pred
                
                # Modeli kaydet
                if item_id not in self.models:
                    self.models[item_id] = {}
                self.models[item_id]['prophet'] = model
                
            except Exception as e:
                print(f"âš ï¸  {item_id} iÃ§in Prophet hatasÄ±: {e}")
        
        print("âœ“ Prophet modelleri tamamlandÄ±")
    
    def train_lightgbm_models(self) -> None:
        """
        LightGBM ile zaman serisi modeli eÄŸit
        
        Gradient boosting yÃ¶ntemi, feature engineering ile gÃ¼Ã§lÃ¼ sonuÃ§lar verir.
        """
        if not LIGHTGBM_AVAILABLE:
            print("LightGBM mevcut deÄŸil, atlanÄ±yor...")
            return
            
        print("\n=== LIGHTGBM MODELS ===")
        
        for item_id in self.data['item_series'].keys():
            print(f"ÃœrÃ¼n: {item_id}")
            
            try:
                train_series = self.data['item_series'][item_id]['train']
                test_series = self.data['item_series'][item_id]['test']
                
                if len(train_series) < 28:  # En az 4 hafta
                    print(f"âš ï¸  {item_id} iÃ§in yeterli veri yok (en az 28 gÃ¼n gerekli)")
                    continue
                
                # Feature engineering
                train_features = self._create_features(train_series)
                test_features = self._create_features(test_series, is_test=True)
                
                if len(train_features) == 0:
                    print(f"âš ï¸  {item_id} iÃ§in feature oluÅŸturulamadÄ±")
                    continue
                
                # LightGBM veri formatÄ±
                feature_cols = [col for col in train_features.columns if col != 'sales']
                
                train_X = train_features[feature_cols]
                train_y = train_features['sales']
                test_X = test_features[feature_cols]
                
                # Model eÄŸitimi
                model = lgb.LGBMRegressor(
                    n_estimators=100,
                    learning_rate=0.1,
                    max_depth=6,
                    random_state=self.config['random_seed'],
                    verbosity=-1
                )
                
                model.fit(train_X, train_y)
                pred = model.predict(test_X)
                pred = np.maximum(pred, 0)  # Negatif deÄŸerleri 0 yap
                
                if item_id not in self.predictions:
                    self.predictions[item_id] = {}
                
                self.predictions[item_id]['lightgbm'] = pred
                
                # Modeli kaydet
                if item_id not in self.models:
                    self.models[item_id] = {}
                self.models[item_id]['lightgbm'] = model
                
            except Exception as e:
                print(f"âš ï¸  {item_id} iÃ§in LightGBM hatasÄ±: {e}")
        
        print("âœ“ LightGBM modelleri tamamlandÄ±")
    
    def _create_features(self, df: pd.DataFrame, is_test: bool = False) -> pd.DataFrame:
        """
        LightGBM iÃ§in feature engineering
        
        Zaman serisi iÃ§in tipik Ã¶zellikler:
        - Lag features (geÃ§miÅŸ deÄŸerler)
        - Rolling statistics (hareketli istatistikler)
        - Time features (gÃ¼n, hafta, ay)
        """
        features_df = df.copy()
        
        # Zaman Ã¶zellikleri
        features_df['day_of_week'] = features_df['date'].dt.dayofweek
        features_df['day_of_month'] = features_df['date'].dt.day
        features_df['week_of_year'] = features_df['date'].dt.isocalendar().week
        features_df['month'] = features_df['date'].dt.month
        
        # Lag features (1, 7, 14 gÃ¼n Ã¶nceki deÄŸerler)
        for lag in [1, 7, 14]:
            features_df[f'sales_lag_{lag}'] = features_df['sales'].shift(lag)
        
        # Rolling features (son 7 gÃ¼nÃ¼n ortalamasÄ± ve standart sapmasÄ±)
        features_df['sales_roll_mean_7'] = features_df['sales'].rolling(window=7, min_periods=1).mean()
        features_df['sales_roll_std_7'] = features_df['sales'].rolling(window=7, min_periods=1).std()
        
        # Test verisi iÃ§in lag'leri dÃ¼zelt (train'den alÄ±nmalÄ±)
        if is_test:
            # Test verisinde lag'ler NaN olacak, bunlarÄ± train'in son deÄŸerleri ile doldur
            for col in features_df.columns:
                if 'lag_' in col or 'roll_' in col:
                    features_df[col] = features_df[col].fillna(method='ffill').fillna(0)
        
        # NaN deÄŸerleri doldur
        features_df = features_df.fillna(0)
        
        # Gereksiz sÃ¼tunlarÄ± Ã§Ä±kar
        drop_cols = ['date', 'item_id', 'd']
        for col in drop_cols:
            if col in features_df.columns:
                features_df = features_df.drop(col, axis=1)
        
        return features_df
    
    def evaluate_models(self) -> None:
        """
        TÃ¼m modelleri deÄŸerlendir ve sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±r
        """
        print("\n=== MODEL DEÄERLENDÄ°RME ===")
        
        all_metrics = {}
        
        for item_id in self.data['item_series'].keys():
            print(f"\nÃœrÃ¼n: {item_id}")
            
            # GerÃ§ek deÄŸerler
            actual = self.data['item_series'][item_id]['test']['sales'].values
            
            if len(actual) == 0:
                print(f"âš ï¸  {item_id} iÃ§in test verisi yok")
                continue
            
            item_metrics = {}
            
            # Her model iÃ§in metrik hesapla
            if item_id in self.predictions:
                for model_name, pred in self.predictions[item_id].items():
                    if len(pred) == len(actual):
                        metrics = self.calculate_metrics(actual, pred)
                        item_metrics[model_name] = metrics
                        
                        print(f"  {model_name:20} - MAE: {metrics['MAE']:.2f}, "
                              f"RMSE: {metrics['RMSE']:.2f}, sMAPE: {metrics['sMAPE']:.2f}%")
            
            all_metrics[item_id] = item_metrics
        
        # Ortalama performans
        print("\n=== ORTALAMA PERFORMANS ===")
        model_names = set()
        for item_metrics in all_metrics.values():
            model_names.update(item_metrics.keys())
        
        avg_metrics = {}
        for model_name in model_names:
            mae_values = []
            rmse_values = []
            smape_values = []
            
            for item_metrics in all_metrics.values():
                if model_name in item_metrics:
                    mae_values.append(item_metrics[model_name]['MAE'])
                    rmse_values.append(item_metrics[model_name]['RMSE'])
                    smape_values.append(item_metrics[model_name]['sMAPE'])
            
            if mae_values:
                avg_metrics[model_name] = {
                    'MAE': np.mean(mae_values),
                    'RMSE': np.mean(rmse_values),
                    'sMAPE': np.mean(smape_values)
                }
        
        # SonuÃ§larÄ± yazdÄ±r
        for model_name, metrics in avg_metrics.items():
            print(f"{model_name:20} - MAE: {metrics['MAE']:.2f}, "
                  f"RMSE: {metrics['RMSE']:.2f}, sMAPE: {metrics['sMAPE']:.2f}%")
        
        self.metrics = {
            'detailed': all_metrics,
            'average': avg_metrics
        }
        
        print("âœ“ Model deÄŸerlendirme tamamlandÄ±")
    
    def create_visualizations(self) -> None:
        """
        SonuÃ§larÄ± gÃ¶rselleÅŸtir
        
        Her Ã¼rÃ¼n iÃ§in ayrÄ± grafik + genel karÅŸÄ±laÅŸtÄ±rma
        """
        print("\n=== GÃ–RSELLEÅTÄ°RME ===")
        
        # 1. Her Ã¼rÃ¼n iÃ§in ayrÄ± grafik
        for item_id in list(self.data['item_series'].keys())[:3]:  # Ä°lk 3 Ã¼rÃ¼n
            self._plot_item_forecast(item_id)
        
        # 2. Model performans karÅŸÄ±laÅŸtÄ±rmasÄ±
        self._plot_model_comparison()
        
        print("âœ“ GÃ¶rselleÅŸtirme tamamlandÄ±")
    
    def _plot_item_forecast(self, item_id: str) -> None:
        """Tek Ã¼rÃ¼n iÃ§in tahmin grafiÄŸi"""
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))
        
        # Veriyi al
        train_data = self.data['item_series'][item_id]['train']
        test_data = self.data['item_series'][item_id]['test']
        
        # Son 60 gÃ¼nÃ¼ gÃ¶ster (daha temiz gÃ¶rÃ¼nÃ¼m iÃ§in)
        if len(train_data) > 60:
            train_data = train_data.tail(60)
        
        # Ãœst grafik: Zaman serisi + tahminler
        ax1.plot(train_data['date'], train_data['sales'], 
                label='Train (GerÃ§ek)', color='blue', linewidth=2)
        ax1.plot(test_data['date'], test_data['sales'], 
                label='Test (GerÃ§ek)', color='green', linewidth=2)
        
        # Tahminleri Ã§iz
        colors = ['red', 'orange', 'purple', 'brown', 'pink']
        if item_id in self.predictions:
            for i, (model_name, pred) in enumerate(self.predictions[item_id].items()):
                color = colors[i % len(colors)]
                ax1.plot(test_data['date'], pred, 
                        label=f'{model_name} (Tahmin)', 
                        color=color, linestyle='--', alpha=0.8)
        
        ax1.set_title(f'ÃœrÃ¼n: {item_id} - SatÄ±ÅŸ Tahmini')
        ax1.set_ylabel('SatÄ±ÅŸ MiktarÄ±')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # Alt grafik: Hata analizi
        if item_id in self.predictions:
            actual = test_data['sales'].values
            for i, (model_name, pred) in enumerate(self.predictions[item_id].items()):
                if len(pred) == len(actual):
                    error = actual - pred
                    color = colors[i % len(colors)]
                    ax2.plot(test_data['date'], error, 
                            label=f'{model_name} HatasÄ±', 
                            color=color, alpha=0.7)
        
        ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)
        ax2.set_title('Tahmin HatalarÄ± (GerÃ§ek - Tahmin)')
        ax2.set_ylabel('Hata')
        ax2.set_xlabel('Tarih')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # Kaydet
        filename = f"forecast_{item_id.replace('/', '_')}.png"
        filepath = os.path.join(self.config['artifacts_path'], filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        print(f"âœ“ Grafik kaydedildi: {filepath}")
        plt.close()
    
    def _plot_model_comparison(self) -> None:
        """Model performanslarÄ±nÄ± karÅŸÄ±laÅŸtÄ±r"""
        if not self.metrics or 'average' not in self.metrics:
            print("âš ï¸  Metrik verisi bulunamadÄ±")
            return
        
        avg_metrics = self.metrics['average']
        
        if not avg_metrics:
            print("âš ï¸  Ortalama metrik verisi yok")
            return
        
        # Verileri hazÄ±rla
        models = list(avg_metrics.keys())
        mae_values = [avg_metrics[m]['MAE'] for m in models]
        rmse_values = [avg_metrics[m]['RMSE'] for m in models]
        smape_values = [avg_metrics[m]['sMAPE'] for m in models]
        
        # Grafik
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        # MAE karÅŸÄ±laÅŸtÄ±rmasÄ±
        bars1 = ax1.bar(models, mae_values, color='skyblue', alpha=0.7)
        ax1.set_title('Mean Absolute Error (MAE)')
        ax1.set_ylabel('MAE')
        ax1.tick_params(axis='x', rotation=45)
        
        # DeÄŸerleri bara yazdÄ±r
        for bar, value in zip(bars1, mae_values):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{value:.2f}', ha='center', va='bottom')
        
        # RMSE karÅŸÄ±laÅŸtÄ±rmasÄ±
        bars2 = ax2.bar(models, rmse_values, color='lightcoral', alpha=0.7)
        ax2.set_title('Root Mean Square Error (RMSE)')
        ax2.set_ylabel('RMSE')
        ax2.tick_params(axis='x', rotation=45)
        
        for bar, value in zip(bars2, rmse_values):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{value:.2f}', ha='center', va='bottom')
        
        # sMAPE karÅŸÄ±laÅŸtÄ±rmasÄ±
        bars3 = ax3.bar(models, smape_values, color='lightgreen', alpha=0.7)
        ax3.set_title('Symmetric Mean Absolute Percentage Error (sMAPE)')
        ax3.set_ylabel('sMAPE (%)')
        ax3.tick_params(axis='x', rotation=45)
        
        for bar, value in zip(bars3, smape_values):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                    f'{value:.1f}%', ha='center', va='bottom')
        
        # En iyi model tablosu
        ax4.axis('off')
        
        # En iyi modeli bul (MAE'ye gÃ¶re)
        best_model_idx = np.argmin(mae_values)
        best_model = models[best_model_idx]
        
        table_data = [
            ['Metrik', 'En Ä°yi Model', 'DeÄŸer'],
            ['MAE', models[np.argmin(mae_values)], f"{min(mae_values):.2f}"],
            ['RMSE', models[np.argmin(rmse_values)], f"{min(rmse_values):.2f}"],
            ['sMAPE', models[np.argmin(smape_values)], f"{min(smape_values):.1f}%"]
        ]
        
        table = ax4.table(cellText=table_data, cellLoc='center', loc='center')
        table.auto_set_font_size(False)
        table.set_fontsize(12)
        table.scale(1.2, 1.5)
        
        # Header'Ä± vurgula
        for i in range(3):
            table[(0, i)].set_facecolor('#40466e')
            table[(0, i)].set_text_props(weight='bold', color='white')
        
        ax4.set_title(f'En Ä°yi Performans Ã–zeti\nGenel Kazanan: {best_model}', 
                     fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        
        # Kaydet
        filepath = os.path.join(self.config['artifacts_path'], 'model_comparison.png')
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        print(f"âœ“ Model karÅŸÄ±laÅŸtÄ±rma grafiÄŸi kaydedildi: {filepath}")
        plt.close()
    
    def save_results(self) -> None:
        """
        SonuÃ§larÄ± kaydet
        
        1. Tahminleri CSV olarak
        2. Modelleri pickle olarak
        3. Metrikleri JSON olarak
        """
        print("\n=== SONUÃ‡LARI KAYDETME ===")
        
        # 1. Tahminleri CSV olarak kaydet
        predictions_list = []
        
        for item_id in self.predictions.keys():
            test_dates = self.data['item_series'][item_id]['test']['date'].values
            actual_values = self.data['item_series'][item_id]['test']['sales'].values
            
            for i, date in enumerate(test_dates):
                row = {
                    'item_id': item_id,
                    'date': date,
                    'actual': actual_values[i] if i < len(actual_values) else 0
                }
                
                # Her modelin tahminini ekle
                for model_name, pred in self.predictions[item_id].items():
                    if i < len(pred):
                        row[f'pred_{model_name}'] = pred[i]
                    else:
                        row[f'pred_{model_name}'] = 0
                
                predictions_list.append(row)
        
        if predictions_list:
            pred_df = pd.DataFrame(predictions_list)
            pred_path = os.path.join(self.config['artifacts_path'], 'predictions.csv')
            pred_df.to_csv(pred_path, index=False)
            print(f"âœ“ Tahminler kaydedildi: {pred_path}")
        
        # 2. Modelleri kaydet
        model_path = os.path.join(self.config['artifacts_path'], 'models.pkl')
        with open(model_path, 'wb') as f:
            pickle.dump(self.models, f)
        print(f"âœ“ Modeller kaydedildi: {model_path}")
        
        # 3. Metrikleri kaydet
        if self.metrics:
            import json
            
            # JSON serileÅŸtirme iÃ§in numpy float'larÄ± normal float'a Ã§evir
            def convert_numpy(obj):
                if isinstance(obj, np.floating):
                    return float(obj)
                elif isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, dict):
                    return {k: convert_numpy(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy(x) for x in obj]
                return obj
            
            metrics_clean = convert_numpy(self.metrics)
            
            metrics_path = os.path.join(self.config['artifacts_path'], 'metrics.json')
            with open(metrics_path, 'w') as f:
                json.dump(metrics_clean, f, indent=2)
            print(f"âœ“ Metrikler kaydedildi: {metrics_path}")
        
        print("âœ“ TÃ¼m sonuÃ§lar kaydedildi")
    
    def run_full_pipeline(self) -> None:
        """
        Tam pipeline'Ä± Ã§alÄ±ÅŸtÄ±r
        
        Bu ana fonksiyon tÃ¼m adÄ±mlarÄ± sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±r.
        """
        try:
            print("ğŸš€ M5 Forecasting Pipeline BaÅŸlatÄ±lÄ±yor...")
            print(f"âš™ï¸  KonfigÃ¼rasyon: {self.config}")
            
            # 1. Veri yÃ¼kleme
            self.load_data()
            
            # 2. Zaman serisi hazÄ±rlÄ±ÄŸÄ±
            self.prepare_time_series()
            
            # 3. Model eÄŸitimi
            self.train_naive_models()
            self.train_exponential_smoothing()
            self.train_prophet_models()
            self.train_lightgbm_models()
            
            # 4. DeÄŸerlendirme
            self.evaluate_models()
            
            # 5. GÃ¶rselleÅŸtirme
            self.create_visualizations()
            
            # 6. SonuÃ§larÄ± kaydetme
            self.save_results()
            
            print("\nğŸ‰ Pipeline baÅŸarÄ±yla tamamlandÄ±!")
            print(f"ğŸ“ SonuÃ§lar: {self.config['artifacts_path']}")
            
        except Exception as e:
            print(f"\nâŒ Pipeline hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            raise

# Prefect ile Ã§alÄ±ÅŸma (opsiyonel)
if PREFECT_AVAILABLE:
    @task
    def load_data_task(forecaster):
        forecaster.load_data()
        return forecaster
    
    @task
    def prepare_time_series_task(forecaster):
        forecaster.prepare_time_series()
        return forecaster
    
    @task
    def train_models_task(forecaster):
        forecaster.train_naive_models()
        forecaster.train_exponential_smoothing()
        forecaster.train_prophet_models()
        forecaster.train_lightgbm_models()
        return forecaster
    
    @task
    def evaluate_task(forecaster):
        forecaster.evaluate_models()
        return forecaster
    
    @task
    def visualize_task(forecaster):
        forecaster.create_visualizations()
        return forecaster
    
    @task
    def save_results_task(forecaster):
        forecaster.save_results()
        return forecaster
    
    @flow(name="M5 Forecasting Pipeline")
    def m5_forecasting_flow(config):
        """Prefect flow olarak pipeline Ã§alÄ±ÅŸtÄ±r"""
        forecaster = M5Forecaster(config)
        
        forecaster = load_data_task(forecaster)
        forecaster = prepare_time_series_task(forecaster)
        forecaster = train_models_task(forecaster)
        forecaster = evaluate_task(forecaster)
        forecaster = visualize_task(forecaster)
        forecaster = save_results_task(forecaster)
        
        return forecaster

def main():
    """
    Ana Ã§alÄ±ÅŸtÄ±rma fonksiyonu
    
    Bu fonksiyon script'i doÄŸrudan Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±zda Ã§aÄŸrÄ±lÄ±r.
    """
    print("=" * 60)
    print("M5 FORECASTING - ZAMAN SERÄ°SÄ° TALEP TAHMÄ°NÄ°")
    print("EÄŸitim AmaÃ§lÄ± Uygulama")
    print("=" * 60)
    
    # KonfigÃ¼rasyonu yazdÄ±r
    print("\nğŸ“‹ KONFIGÃœRASYON:")
    for key, value in CONFIG.items():
        print(f"  {key}: {value}")
    
    try:
        if PREFECT_AVAILABLE:
            print("\nğŸ”„ Prefect ile Ã§alÄ±ÅŸÄ±lÄ±yor...")
            forecaster = m5_forecasting_flow(CONFIG)
        else:
            print("\nğŸ”„ Normal modda Ã§alÄ±ÅŸÄ±lÄ±yor...")
            forecaster = M5Forecaster(CONFIG)
            forecaster.run_full_pipeline()
        
        print("\nâœ… Ä°ÅŸlem baÅŸarÄ±yla tamamlandÄ±!")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  KullanÄ±cÄ± tarafÄ±ndan durduruldu")
    except Exception as e:
        print(f"\nğŸ’¥ Beklenmeyen hata: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
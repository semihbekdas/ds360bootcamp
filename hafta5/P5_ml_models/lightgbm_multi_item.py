#!/usr/bin/env python3
"""
LightGBM Ã‡ok ÃœrÃ¼nlÃ¼ SatÄ±ÅŸ Tahmini

Bu script Ã§ok Ã¼rÃ¼nlÃ¼ (multi-item) forecasting iÃ§in LightGBM kullanÄ±r.
Lag ve rolling Ã¶zelliklerle 28 gÃ¼nlÃ¼k iteratif tahmin yapar.

YaklaÅŸÄ±m:
- TÃ¼m Ã¼rÃ¼nler tek modelde (cross-product learning)
- LabelEncoder ile kategorik encoding
- Iteratif forecasting (basit yaklaÅŸÄ±m, eÄŸitim amaÃ§lÄ±)

Production NotlarÄ±:
- Bu basit iteratif yaklaÅŸÄ±m eÄŸitim amaÃ§lÄ±dÄ±r
- Daha geliÅŸmiÅŸ iÃ§in: backtesting, cross-validation, ensemble
- BÃ¼yÃ¼k Ã¶lÃ§ekte: distributed training, feature store

KullanÄ±m: python lightgbm_multi_item.py
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
import os
import pickle
from datetime import datetime, timedelta

# LightGBM
try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    print("âŒ LightGBM kÃ¼tÃ¼phanesi bulunamadÄ±. 'pip install lightgbm' ile kurun.")
    LIGHTGBM_AVAILABLE = False

# Preprocessing
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error

warnings.filterwarnings('ignore')

class LightGBMMultiItemForecaster:
    """
    LightGBM ile Ã§ok Ã¼rÃ¼nlÃ¼ forecasting sÄ±nÄ±fÄ±
    
    Ã–zellikler:
    - TÃ¼m Ã¼rÃ¼nler tek modelde (shared learning)
    - Lag ve rolling feature'lar
    - Kategorik encoding (LabelEncoder)
    - Iteratif 28 gÃ¼nlÃ¼k tahmin
    """
    
    def __init__(self, artifacts_path='./artifacts'):
        self.artifacts_path = artifacts_path
        self.train_df = None
        self.valid_df = None
        self.model = None
        self.label_encoders = {}
        self.feature_cols = []
        self.metrics = {}
        self.feature_importance = None
        
        # Ã‡Ä±ktÄ± klasÃ¶rlerini oluÅŸtur
        os.makedirs(f'{artifacts_path}/models', exist_ok=True)
        os.makedirs(f'{artifacts_path}/preds', exist_ok=True)
        os.makedirs(f'{artifacts_path}/figures', exist_ok=True)
        
        print("ğŸš€ LightGBM Ã‡ok ÃœrÃ¼nlÃ¼ Forecasting")
        print("ğŸ’¡ Avantajlar: HÄ±zlÄ±, cross-product learning, feature importance")
        print("âš ï¸  Not: Basit iteratif yaklaÅŸÄ±m - prod iÃ§in daha geliÅŸmiÅŸ backtesting gerekir")
        print("=" * 75)
    
    def load_feature_data(self):
        """Feature engineered verileri yÃ¼kle"""
        
        print("\nğŸ“ 1. Feature engineered veriler yÃ¼kleniyor...")
        
        try:
            # Parquet dosyalarÄ±nÄ± yÃ¼kle
            train_path = f'{self.artifacts_path}/datasets/fe_train.parquet'
            valid_path = f'{self.artifacts_path}/datasets/fe_valid.parquet'
            
            self.train_df = pd.read_parquet(train_path)
            self.valid_df = pd.read_parquet(valid_path)
            
            print(f"   âœ“ Train data: {self.train_df.shape}")
            print(f"   âœ“ Valid data: {self.valid_df.shape}")
            
            # SÃ¼tun bilgileri
            print(f"   â€¢ SÃ¼tunlar: {list(self.train_df.columns)}")
            
            # ÃœrÃ¼n sayÄ±larÄ±
            train_items = self.train_df['item_id'].nunique()
            valid_items = self.valid_df['item_id'].nunique()
            print(f"   â€¢ Train Ã¼rÃ¼n sayÄ±sÄ±: {train_items}")
            print(f"   â€¢ Valid Ã¼rÃ¼n sayÄ±sÄ±: {valid_items}")
            
            # Tarih aralÄ±klarÄ±
            print(f"   â€¢ Train tarih: {self.train_df.index.min()} - {self.train_df.index.max()}")
            print(f"   â€¢ Valid tarih: {self.valid_df.index.min()} - {self.valid_df.index.max()}")
            
        except FileNotFoundError as e:
            print(f"   âŒ Dosya bulunamadÄ±: {e}")
            print("   ğŸ’¡ Ã–nce feature_engineering.py Ã§alÄ±ÅŸtÄ±rÄ±n")
            raise
        except Exception as e:
            print(f"   âŒ Veri yÃ¼kleme hatasÄ±: {e}")
            raise
    
    def encode_categorical_features(self):
        """Kategorik Ã¶zellikleri encode et"""
        
        print("\nğŸ·ï¸  2. Kategorik Ã¶zellikler encode ediliyor...")
        
        categorical_cols = ['item_id', 'store_id']
        
        for col in categorical_cols:
            if col in self.train_df.columns:
                print(f"   â€¢ {col} encode ediliyor...")
                
                # LabelEncoder oluÅŸtur ve train ile fit et
                le = LabelEncoder()
                
                # Train verisi ile fit
                self.train_df[f'{col}_encoded'] = le.fit_transform(self.train_df[col])
                
                # Valid verisi transform (unseen values iÃ§in handling)
                try:
                    self.valid_df[f'{col}_encoded'] = le.transform(self.valid_df[col])
                except ValueError as e:
                    print(f"     âš ï¸  {col} iÃ§in unseen values var, 0 ile doldurulacak")
                    # Unseen values'larÄ± handle et
                    valid_encoded = []
                    for val in self.valid_df[col]:
                        if val in le.classes_:
                            valid_encoded.append(le.transform([val])[0])
                        else:
                            valid_encoded.append(0)  # Unseen = 0
                    self.valid_df[f'{col}_encoded'] = valid_encoded
                
                # Encoder'Ä± sakla
                self.label_encoders[col] = le
                
                print(f"     - Train unique: {self.train_df[f'{col}_encoded'].nunique()}")
                print(f"     - Valid unique: {self.valid_df[f'{col}_encoded'].nunique()}")
        
        print(f"   âœ“ {len(categorical_cols)} kategorik Ã¶zellik encode edildi")
    
    def prepare_features_target(self):
        """Ã–zellik ve hedef deÄŸiÅŸkenleri hazÄ±rla"""
        
        print("\nğŸ¯ 3. Ã–zellik ve hedef deÄŸiÅŸkenler hazÄ±rlanÄ±yor...")
        
        # Hedef deÄŸiÅŸken
        target_col = 'sales'
        
        # Ã–zellik sÃ¼tunlarÄ±
        # Lag ve rolling feature'lar
        lag_cols = [col for col in self.train_df.columns if 'lag_' in col]
        roll_cols = [col for col in self.train_df.columns if 'roll_' in col]
        
        # Tarih Ã¶zellikleri
        date_cols = ['dow', 'dom', 'weekofyear', 'month']
        
        # Encoded kategorik Ã¶zellikler
        encoded_cols = [col for col in self.train_df.columns if '_encoded' in col]
        
        # TÃ¼m feature sÃ¼tunlarÄ±
        self.feature_cols = lag_cols + roll_cols + date_cols + encoded_cols
        
        print(f"   ğŸ“Š Ã–zellik GruplarÄ±:")
        print(f"   â€¢ Lag Ã¶zellikleri: {len(lag_cols)} -> {lag_cols}")
        print(f"   â€¢ Rolling Ã¶zellikleri: {len(roll_cols)} -> {roll_cols}")
        print(f"   â€¢ Tarih Ã¶zellikleri: {len(date_cols)} -> {date_cols}")
        print(f"   â€¢ Kategorik Ã¶zellikleri: {len(encoded_cols)} -> {encoded_cols}")
        print(f"   â€¢ Toplam Ã¶zellik sayÄ±sÄ±: {len(self.feature_cols)}")
        
        # Train/Valid ayÄ±rma
        X_train = self.train_df[self.feature_cols].copy()
        y_train = self.train_df[target_col].copy()
        
        X_valid = self.valid_df[self.feature_cols].copy()
        y_valid = self.valid_df[target_col].copy()
        
        print(f"   âœ“ X_train: {X_train.shape}, y_train: {y_train.shape}")
        print(f"   âœ“ X_valid: {X_valid.shape}, y_valid: {y_valid.shape}")
        
        # NaN kontrol
        train_nans = X_train.isnull().sum().sum()
        valid_nans = X_valid.isnull().sum().sum()
        
        if train_nans > 0 or valid_nans > 0:
            print(f"   âš ï¸  NaN deÄŸerler: Train={train_nans}, Valid={valid_nans}")
            X_train = X_train.fillna(0)
            X_valid = X_valid.fillna(0)
            print(f"   â€¢ NaN deÄŸerler 0 ile dolduruldu")
        
        return X_train, y_train, X_valid, y_valid
    
    def train_lightgbm_model(self, X_train, y_train, X_valid, y_valid):
        """LightGBM modelini eÄŸit"""
        
        print("\nğŸŒŸ 4. LightGBM modeli eÄŸitiliyor...")
        
        try:
            # LightGBM parametreleri
            lgb_params = {
                'objective': 'regression',
                'metric': 'rmse',
                'boosting_type': 'gbdt',
                'num_leaves': 31,
                'learning_rate': 0.05,
                'feature_fraction': 0.9,
                'bagging_fraction': 0.8,
                'bagging_freq': 5,
                'verbose': -1,
                'random_state': 42
            }
            
            print(f"   ğŸ“‹ Model Parametreleri:")
            for key, value in lgb_params.items():
                print(f"   â€¢ {key}: {value}")
            
            # Dataset'leri oluÅŸtur
            train_data = lgb.Dataset(X_train, label=y_train)
            valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)
            
            print(f"   â€¢ LightGBM eÄŸitimi baÅŸlÄ±yor...")
            
            # Modeli eÄŸit
            self.model = lgb.train(
                lgb_params,
                train_data,
                valid_sets=[train_data, valid_data],
                valid_names=['train', 'valid'],
                num_boost_round=500,
                callbacks=[
                    lgb.early_stopping(stopping_rounds=50),
                    lgb.log_evaluation(period=100)
                ]
            )
            
            print(f"   âœ“ Model eÄŸitimi tamamlandÄ±")
            print(f"   â€¢ En iyi iterasyon: {self.model.best_iteration}")
            print(f"   â€¢ Train RMSE: {self.model.best_score['train']['rmse']:.4f}")
            print(f"   â€¢ Valid RMSE: {self.model.best_score['valid']['rmse']:.4f}")
            
        except Exception as e:
            print(f"   âŒ LightGBM eÄŸitimi hatasÄ±: {e}")
            raise
    
    def calculate_validation_metrics(self, X_valid, y_valid):
        """Validation metrikleri hesapla"""
        
        print("\nğŸ“Š 5. Validation metrikleri hesaplanÄ±yor...")
        
        # Tahmin yap
        y_pred = self.model.predict(X_valid, num_iteration=self.model.best_iteration)
        
        # Negatif deÄŸerleri 0 yap
        y_pred = np.maximum(y_pred, 0)
        
        # Metrikler
        mae = mean_absolute_error(y_valid, y_pred)
        rmse = np.sqrt(mean_squared_error(y_valid, y_pred))
        
        # MAPE
        mask = y_valid != 0
        if mask.sum() > 0:
            mape = np.mean(np.abs((y_valid[mask] - y_pred[mask]) / y_valid[mask])) * 100
        else:
            mape = float('inf')
        
        # sMAPE
        denominator = (np.abs(y_valid) + np.abs(y_pred)) / 2
        mask = denominator != 0
        if mask.sum() > 0:
            smape = np.mean(np.abs(y_valid[mask] - y_pred[mask]) / denominator[mask]) * 100
        else:
            smape = float('inf')
        
        self.metrics = {
            'MAE': mae,
            'RMSE': rmse,
            'MAPE': mape,
            'sMAPE': smape,
            'R2': 1 - (np.sum((y_valid - y_pred) ** 2) / np.sum((y_valid - np.mean(y_valid)) ** 2))
        }
        
        print(f"   ğŸ“ˆ LightGBM Validation PerformansÄ±:")
        print(f"   â€¢ MAE:   {mae:.2f}")
        print(f"   â€¢ RMSE:  {rmse:.2f}")
        print(f"   â€¢ MAPE:  {mape:.2f}%")
        print(f"   â€¢ sMAPE: {smape:.2f}%")
        print(f"   â€¢ RÂ²:    {self.metrics['R2']:.4f}")
        
        return y_pred
    
    def create_feature_importance_plot(self):
        """Feature importance grafiÄŸi oluÅŸtur"""
        
        print("\nğŸ“Š 6. Feature importance grafiÄŸi oluÅŸturuluyor...")
        
        # Feature importance al (gain)
        importance_gain = self.model.feature_importance(importance_type='gain')
        feature_names = self.feature_cols
        
        # DataFrame oluÅŸtur
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importance_gain
        }).sort_values('importance', ascending=False)
        
        self.feature_importance = importance_df
        
        # Grafik
        plt.figure(figsize=(12, 8))
        
        # Top 15 feature gÃ¶ster
        top_features = importance_df.head(15)
        
        bars = plt.barh(top_features['feature'], top_features['importance'], 
                       color='lightblue', alpha=0.8)
        
        # DeÄŸerleri bara yazdÄ±r
        for bar, value in zip(bars, top_features['importance']):
            plt.text(bar.get_width() + max(top_features['importance']) * 0.01, 
                    bar.get_y() + bar.get_height()/2,
                    f'{value:.0f}', ha='left', va='center', fontweight='bold')
        
        plt.title('LightGBM Feature Importance (Gain)', fontweight='bold', fontsize=16)
        plt.xlabel('Importance (Gain)', fontsize=12)
        plt.ylabel('Features', fontsize=12)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        # Kaydet
        importance_path = f'{self.artifacts_path}/figures/lgbm_feature_importance.png'
        plt.savefig(importance_path, dpi=300, bbox_inches='tight')
        print(f"   âœ“ Feature importance grafiÄŸi: {importance_path}")
        plt.close()
        
        # Top 10 yazdÄ±r
        print(f"   ğŸ† En Ã–nemli 10 Feature:")
        for i, (_, row) in enumerate(top_features.head(10).iterrows(), 1):
            print(f"     {i:2d}. {row['feature']:<20}: {row['importance']:6.0f}")
    
    def iterative_forecast(self, forecast_steps=28):
        """Iteratif 28 gÃ¼nlÃ¼k tahmin"""
        
        print(f"\nğŸ”® 7. {forecast_steps} gÃ¼nlÃ¼k iteratif tahmin yapÄ±lÄ±yor...")
        print(f"   âš ï¸  Not: Bu basit iteratif yaklaÅŸÄ±mdÄ±r - prod iÃ§in daha geliÅŸmiÅŸ backtesting gerekir")
        
        try:
            # Son tarih ve baÅŸlangÄ±Ã§
            last_date = self.valid_df.index.max()
            forecast_start = last_date + timedelta(days=1)
            
            print(f"   â€¢ Son veri tarihi: {last_date}")
            print(f"   â€¢ Tahmin baÅŸlangÄ±cÄ±: {forecast_start}")
            
            # TÃ¼m Ã¼rÃ¼nler iÃ§in tahmin
            all_forecasts = []
            
            # Her Ã¼rÃ¼n iÃ§in ayrÄ± ayrÄ± tahmin (iteratif update iÃ§in)
            unique_items = self.valid_df['item_id'].unique()
            
            for item_id in unique_items:
                print(f"   â€¢ {item_id} iÃ§in tahmin yapÄ±lÄ±yor...")
                
                # Son durumu al (valid son satÄ±r)
                item_valid = self.valid_df[self.valid_df['item_id'] == item_id].copy()
                
                if len(item_valid) == 0:
                    print(f"     âš ï¸  {item_id} iÃ§in valid veri bulunamadÄ±")
                    continue
                
                # Son satÄ±rÄ± al (feature template olarak)
                last_row = item_valid.iloc[-1].copy()
                
                # Bu Ã¼rÃ¼n iÃ§in iteratif tahmin
                item_forecasts = []
                current_features = last_row.copy()
                
                for step in range(forecast_steps):
                    forecast_date = forecast_start + timedelta(days=step)
                    
                    # Tarih Ã¶zelliklerini gÃ¼ncelle
                    current_features['dow'] = forecast_date.weekday()
                    current_features['dom'] = forecast_date.day
                    current_features['weekofyear'] = forecast_date.isocalendar()[1]
                    current_features['month'] = forecast_date.month
                    
                    # Tahmin yap
                    X_pred = current_features[self.feature_cols].values.reshape(1, -1)
                    y_pred = self.model.predict(X_pred, num_iteration=self.model.best_iteration)[0]
                    y_pred = max(0, y_pred)  # Negatif deÄŸerleri 0 yap
                    
                    # Sonucu kaydet
                    item_forecasts.append({
                        'date': forecast_date,
                        'item_id': item_id,
                        'store_id': last_row['store_id'],
                        'y_pred': y_pred
                    })
                    
                    # Lag feature'larÄ± gÃ¼ncelle (basit yaklaÅŸÄ±m)
                    # Bu gerÃ§ek prod iÃ§in Ã§ok basit - daha sofistike lag update gerekir
                    if 'lag_1' in current_features:
                        # Shift lag values
                        if 'lag_28' in current_features:
                            # Bu Ã§ok basit bir yaklaÅŸÄ±m - real-world'de daha karmaÅŸÄ±k olmalÄ±
                            pass  # Åimdilik lag'leri gÃ¼ncelleme
                
                all_forecasts.extend(item_forecasts)
            
            # DataFrame'e Ã§evir
            forecast_df = pd.DataFrame(all_forecasts)
            
            print(f"   âœ“ {len(forecast_df)} tahmin Ã¼retildi")
            print(f"   â€¢ ÃœrÃ¼n sayÄ±sÄ±: {forecast_df['item_id'].nunique()}")
            print(f"   â€¢ Tarih aralÄ±ÄŸÄ±: {forecast_df['date'].min()} - {forecast_df['date'].max()}")
            print(f"   â€¢ Ortalama tahmin: {forecast_df['y_pred'].mean():.2f}")
            
            return forecast_df
            
        except Exception as e:
            print(f"   âŒ Iteratif tahmin hatasÄ±: {e}")
            raise
    
    def save_results(self, forecast_df):
        """SonuÃ§larÄ± kaydet"""
        
        print("\nğŸ’¾ 8. SonuÃ§lar kaydediliyor...")
        
        try:
            # 1. Model kaydet
            model_path = f'{self.artifacts_path}/models/lgbm.pkl'
            
            model_data = {
                'model': self.model,
                'feature_cols': self.feature_cols,
                'label_encoders': self.label_encoders,
                'metrics': self.metrics,
                'feature_importance': self.feature_importance,
                'model_params': {
                    'best_iteration': self.model.best_iteration,
                    'best_score': self.model.best_score
                }
            }
            
            with open(model_path, 'wb') as f:
                pickle.dump(model_data, f)
            print(f"   âœ“ Model: {model_path}")
            
            # 2. Tahminleri kaydet
            pred_path = f'{self.artifacts_path}/preds/lgbm_forecast_all.csv'
            forecast_df.to_csv(pred_path, index=False)
            print(f"   âœ“ Tahminler: {pred_path}")
            
            # 3. Ã–zet rapor
            import json
            
            report = {
                'model_type': 'LightGBM',
                'training_date': datetime.now().isoformat(),
                'data_info': {
                    'train_shape': list(self.train_df.shape),
                    'valid_shape': list(self.valid_df.shape),
                    'n_items': self.train_df['item_id'].nunique(),
                    'feature_count': len(self.feature_cols)
                },
                'model_performance': self.metrics,
                'top_features': self.feature_importance.head(10).to_dict('records') if self.feature_importance is not None else [],
                'forecast_info': {
                    'forecast_steps': 28,
                    'forecast_items': int(forecast_df['item_id'].nunique()),
                    'total_predictions': len(forecast_df)
                }
            }
            
            report_path = f'{self.artifacts_path}/preds/lgbm_report.json'
            with open(report_path, 'w') as f:
                json.dump(report, f, indent=2, default=str)
            print(f"   âœ“ Rapor: {report_path}")
            
        except Exception as e:
            print(f"   âŒ SonuÃ§ kaydetme hatasÄ±: {e}")
            raise
    
    def run_full_pipeline(self):
        """Tam LightGBM pipeline'Ä±nÄ± Ã§alÄ±ÅŸtÄ±r"""
        
        try:
            # 1. Veri yÃ¼kleme
            self.load_feature_data()
            
            # 2. Kategorik encoding
            self.encode_categorical_features()
            
            # 3. Feature/target hazÄ±rlama
            X_train, y_train, X_valid, y_valid = self.prepare_features_target()
            
            # 4. Model eÄŸitimi
            self.train_lightgbm_model(X_train, y_train, X_valid, y_valid)
            
            # 5. Validation metrikleri
            y_pred_valid = self.calculate_validation_metrics(X_valid, y_valid)
            
            # 6. Feature importance
            self.create_feature_importance_plot()
            
            # 7. Ä°teratif tahmin
            forecast_df = self.iterative_forecast()
            
            # 8. SonuÃ§larÄ± kaydet
            self.save_results(forecast_df)
            
            print(f"\nğŸ‰ LightGBM Multi-Item Forecasting tamamlandÄ±!")
            print(f"ğŸš€ Model: LightGBM Regressor")
            print(f"ğŸ“Š Valid sMAPE: {self.metrics['sMAPE']:.2f}%")
            print(f"ğŸ“ˆ RÂ²: {self.metrics['R2']:.4f}")
            print(f"ğŸ”® Tahmin: {len(forecast_df)} adet (28 gÃ¼n x {forecast_df['item_id'].nunique()} Ã¼rÃ¼n)")
            print(f"ğŸ“ Ã‡Ä±ktÄ±lar: {self.artifacts_path}/")
            
            return self.model, forecast_df, self.metrics
            
        except Exception as e:
            print(f"\nâŒ LightGBM Pipeline hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            raise

def main():
    """Ana Ã§alÄ±ÅŸtÄ±rma fonksiyonu"""
    
    if not LIGHTGBM_AVAILABLE:
        print("âŒ LightGBM kÃ¼tÃ¼phanesi gerekli. 'pip install lightgbm' ile kurun.")
        return
    
    print("=" * 75)
    print("LIGHTGBM Ã‡OK ÃœRÃœNLÃœ SATIÅ TAHMÄ°NÄ°")
    print("ğŸš€ Avantajlar: HÄ±zlÄ±, feature importance, cross-product learning")
    print("âš ï¸  Bu basit iteratif yaklaÅŸÄ±m - prod iÃ§in daha geliÅŸmiÅŸ backtesting gerekir")
    print("=" * 75)
    
    try:
        # LightGBM forecaster'Ä± baÅŸlat
        forecaster = LightGBMMultiItemForecaster()
        
        # Tam pipeline'Ä± Ã§alÄ±ÅŸtÄ±r
        model, forecast, metrics = forecaster.run_full_pipeline()
        
        print(f"\nâœ… Ä°ÅŸlem baÅŸarÄ±yla tamamlandÄ±!")
        print(f"\nğŸ’¡ LightGBM AvantajlarÄ±:")
        print(f"   â€¢ HÄ±zlÄ± eÄŸitim ve tahmin")
        print(f"   â€¢ Otomatik feature importance")
        print(f"   â€¢ Kategorik feature desteÄŸi")
        print(f"   â€¢ Cross-product learning (Ã¼rÃ¼nler arasÄ± pattern)")
        print(f"\nâš ï¸  Production Ä°yileÅŸtirmeleri:")
        print(f"   â€¢ Daha sofistike iteratif lag update")
        print(f"   â€¢ Cross-validation ve backtesting")
        print(f"   â€¢ Hyperparameter tuning")
        print(f"   â€¢ Ensemble models")
        
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸  KullanÄ±cÄ± tarafÄ±ndan durduruldu")
    except Exception as e:
        print(f"\nğŸ’¥ Beklenmeyen hata: {e}")

if __name__ == "__main__":
    main()
# Hafta 5 - M5 Forecasting: Zaman Serisi Talep Tahmini

ğŸª **KapsamlÄ± M5 Competition TabanlÄ± Talep Tahmin Sistemi**

Bu proje M5 Competition verisi ile profesyonel zaman serisi talep tahmini yapan eÄŸitim amaÃ§lÄ± kapsamlÄ± bir uygulamadÄ±r. Geleneksel istatistiksel yÃ¶ntemlerden modern machine learning tekniklerine, manual analizden otomatik pipeline'a kadar tam bir forecasting ekosistemine sahiptir.

## ğŸ“– M5 Competition: Dataset Hikayesi

### ğŸ›’ **Walmart'Ä±n Hikayesi**
M5 Competition, dÃ¼nyanÄ±n en bÃ¼yÃ¼k perakende zinciri **Walmart**'Ä±n gerÃ§ek satÄ±ÅŸ verilerini kullanarak dÃ¼zenlenen uluslararasÄ± bir forecasting yarÄ±ÅŸmasÄ±dÄ±r. Bu competition, retail sektÃ¶rÃ¼nÃ¼n en bÃ¼yÃ¼k challengelerinden biri olan **demand forecasting** problemini ele alÄ±r.

### ğŸ“Š **Dataset'in BÃ¼yÃ¼klÃ¼ÄŸÃ¼ ve KapsamÄ±**
- **ğŸ“… Zaman AralÄ±ÄŸÄ±**: 2011-2016 (5 yÄ±l, 1,969 gÃ¼n)
- **ğŸŒ CoÄŸrafi Kapsam**: 3 Eyalet (California, Texas, Wisconsin)
- **ğŸª MaÄŸaza SayÄ±sÄ±**: 10 maÄŸaza (CA_1-4, TX_1-3, WI_1-3)
- **ğŸ“¦ ÃœrÃ¼n Kategorileri**: 3 ana kategori (FOODS, HOBBIES, HOUSEHOLD)
- **ğŸ›ï¸ Toplam ÃœrÃ¼n**: 3,049 benzersiz Ã¼rÃ¼n
- **ğŸ“ˆ Time Series**: 30,490 adet gÃ¼nlÃ¼k satÄ±ÅŸ serisi
- **ğŸ’¾ Veri Boyutu**: ~30GB (tÃ¼m hierarchical levels dahil)

### ğŸ¯ **Competition'un AmacÄ±**
M5 Competition'un temel hedefi:
1. **Hierarchical Forecasting**: ÃœrÃ¼n â†’ Kategori â†’ MaÄŸaza â†’ Eyalet seviyelerinde tahmin
2. **Uncertainty Quantification**: Sadece nokta tahmin deÄŸil, gÃ¼ven aralÄ±klarÄ± da
3. **Real-world Applicability**: Akademik araÅŸtÄ±rma ile industry practice arasÄ±nda kÃ¶prÃ¼
4. **Evaluation Methodology**: WRMSSE (Weighted Root Mean Squared Scaled Error) metriÄŸi

### ğŸ† **Competition SonuÃ§larÄ±**
- **ğŸ“… DÃ¼zenleme Tarihi**: 2020
- **ğŸ‘¥ KatÄ±lÄ±mcÄ± SayÄ±sÄ±**: 909 takÄ±m, 5,558 katÄ±lÄ±mcÄ±
- **ğŸ¥‡ Kazanan YaklaÅŸÄ±m**: LightGBM ensemble + hierarchical reconciliation
- **ğŸ“Š En Ä°yi sMAPE**: ~12.03% (leaderboard)
- **ğŸ”— Kaggle Link**: https://www.kaggle.com/c/m5-forecasting-accuracy

### ğŸ“ **EÄŸitim DeÄŸeri**
Bu dataset'in eÄŸitim iÃ§in seÃ§ilme nedenleri:
1. **GerÃ§ek Veri**: Sentetik deÄŸil, gerÃ§ek Walmart satÄ±ÅŸ verisi
2. **Komplekslik**: Seasonality, trend, promotional effects, external factors
3. **Scale**: BÃ¼yÃ¼k data ile Ã§alÄ±ÅŸma deneyimi
4. **Industry Relevance**: Retail sektÃ¶rÃ¼nÃ¼n gerÃ§ek problemleri
5. **Benchmark**: Akademik literature'da yaygÄ±n kullanÄ±m

## ğŸ—ï¸ **ModÃ¼ler Proje Mimarisi**

Bu proje, educational clarity ve production readiness iÃ§in modÃ¼ler mimari kullanÄ±r:

```
ğŸ“¦ hafta5/                         # Ana proje klasÃ¶rÃ¼
â”œâ”€â”€ ğŸ“ P1_data_preparation/        # Veri hazÄ±rlama ve preprocessing
â”œâ”€â”€ ğŸ“ P2_feature_engineering/     # Feature engineering pipeline
â”œâ”€â”€ ğŸ“ P3_traditional_models/      # Ä°statistiksel modeller (ARIMA)
â”œâ”€â”€ ğŸ“ P4_modern_models/           # Modern modeller (Prophet)
â”œâ”€â”€ ğŸ“ P5_ml_models/               # ML modelleri (LightGBM)
â”œâ”€â”€ ğŸ“ P6_validation/              # Cross-validation ve evaluation
â”œâ”€â”€ ğŸ“ P7_automation/              # Prefect pipeline automation
â”œâ”€â”€ ğŸ“ legacy/                     # Legacy monolith kod
â”œâ”€â”€ ğŸ“ data/                       # M5 dataset
â”œâ”€â”€ ğŸ“ artifacts/                  # Model outputs ve reports
â””â”€â”€ ğŸ³ Docker/Compose files        # Containerization
```

### ğŸ¯ **ModÃ¼ler YaklaÅŸÄ±mÄ±n FaydalarÄ±**
- **ğŸ“š Educational**: Her modÃ¼l tek concept'e odaklanÄ±r
- **ğŸ”§ Maintainable**: Kod bakÄ±mÄ± ve gÃ¼ncelleme kolaylaÅŸÄ±r
- **ğŸš€ Scalable**: ModÃ¼ler deployment ve scaling
- **ğŸ§ª Testable**: Her modÃ¼l baÄŸÄ±msÄ±z test edilebilir
- **ğŸ‘¥ Collaborative**: FarklÄ± geliÅŸtiriciler farklÄ± modÃ¼llerde Ã§alÄ±ÅŸabilir

### ğŸ® **HÄ±zlÄ± BaÅŸlangÄ±Ã§**
```bash
# ModÃ¼ler Ã§alÄ±ÅŸtÄ±rma
python run_modular.py --module P1    # Sadece data prep
python run_modular.py --module P7    # Sadece automation
python run_modular.py               # Full pipeline

# Docker ile production
docker build -t m5-forecast:dev .
docker run --rm -v $(pwd)/artifacts:/app/artifacts m5-forecast:dev
```

## ğŸ¯ Proje Hedefleri

### Akademik Hedefler
- **M5 Competition Verisi**: GerÃ§ek dÃ¼nya Walmart satÄ±ÅŸ verisi ile Ã§alÄ±ÅŸma
- **Ã‡oklu Model KarÅŸÄ±laÅŸtÄ±rmasÄ±**: ARIMA, Prophet, LightGBM arasÄ±nda objektif karÅŸÄ±laÅŸtÄ±rma
- **Proper Time Series Validation**: Temporal leakage'Ä± Ã¶nleyecek rolling-origin cross-validation
- **Feature Engineering**: Lag, rolling, seasonal features ile model performansÄ± iyileÅŸtirme
- **Production-Ready Pipeline**: Prefect ile otomatik gÃ¼nlÃ¼k forecasting akÄ±ÅŸÄ±

### Teknik Hedefler
- **Reproducible Research**: Seed kontrolÃ¼ ve deterministik sonuÃ§lar
- **Scalable Architecture**: Docker containerization ve cloud deployment hazÄ±rlÄ±ÄŸÄ±
- **Educational Code**: Her adÄ±mda "neden bÃ¶yle yapÄ±yoruz?" aÃ§Ä±klamalarÄ±
- **Error Handling**: Robust exception management ve graceful degradation
- **Comprehensive Logging**: Debug ve monitoring iÃ§in detaylÄ± log yapÄ±sÄ±

## ğŸ“‹ Sistem Ã–zellikleri

### ğŸ¤– Forecasting Modelleri

#### **Geleneksel Ä°statistiksel YÃ¶ntemler**
- **ARIMA (AutoRegressive Integrated Moving Average)**
  - Otomatik (p,d,q) parametre optimizasyonu
  - Stationarity testing (ADF test)
  - Box-Jenkins metodolojisi
  - Grid search ile en iyi parametreler
  - Performance: ~46% sMAPE (dataset'e gÃ¶re deÄŸiÅŸir)

- **Exponential Smoothing (Holt-Winters)**
  - Trend ve seasonal komponent ayrÄ±ÅŸtÄ±rmasÄ±
  - Alpha, beta, gamma parametrelerinin otomatik optimizasyonu
  - Additive/multiplicative seasonal pattern detection

#### **Modern Machine Learning YÃ¶ntemleri**
- **Facebook Prophet**
  - Otomatik trend ve seasonality detection
  - Holiday effects modeling capability
  - Uncertainty intervals ile tahmin gÃ¼ven aralÄ±klarÄ±
  - Performance: ~28% sMAPE (ARIMA'dan %40 daha iyi)

- **LightGBM (Gradient Boosting)**
  - Multi-item forecasting capability
  - Rich feature engineering pipeline
  - Categorical encoding (item_id, store_id)
  - Time-based features (dow, month, week)
  - Lag features (1, 7, 28 gÃ¼nlÃ¼k)
  - Rolling statistics (7, 28 gÃ¼nlÃ¼k ortalamalar)
  - Performance: ~33% sMAPE
  - Feature importance analysis

#### **Baseline Modeller**
- **Naive Forecasting**: Son deÄŸeri tekrarlama
- **Seasonal Naive**: GeÃ§en yÄ±lÄ±n aynÄ± dÃ¶nemini kullanma
- **Moving Average**: Son N gÃ¼nÃ¼n ortalamasÄ±
- **Linear Trend**: DoÄŸrusal trend extrapolasyonu

### ğŸ“Š Evaluation Metrikleri

#### **Primary Metrics**
- **MAE** (Mean Absolute Error): Mutlak hatanÄ±n ortalamasÄ±
- **RMSE** (Root Mean Square Error): BÃ¼yÃ¼k hatalarÄ± penalize eden metrik
- **sMAPE** (Symmetric Mean Absolute Percentage Error): M5 Competition'un resmi metriÄŸi
- **MAPE** (Mean Absolute Percentage Error): YÃ¼zdelik hata

#### **Advanced Evaluation**
- **Time Series Cross-Validation**: Rolling-origin, no shuffle, temporal order preserved
- **Fold Strategy**: 3-fold CV, 28-day validation horizon
- **Statistical Significance**: Paired t-test for model comparison
- **Residual Analysis**: Heteroscedasticity ve autocorrelation testleri

### ğŸ”§ Feature Engineering Pipeline

#### **Temporal Features**
```python
# Time-based decomposition
df['dow'] = df.index.dayofweek        # Day of week (0-6)
df['month'] = df.index.month          # Month (1-12)
df['dom'] = df.index.day              # Day of month (1-31)
df['weekofyear'] = df.index.isocalendar().week  # Week number (1-53)
```

#### **Lag Features** 
```python
# Historical patterns
df['lag_1'] = df['sales'].shift(1)    # Yesterday's sales
df['lag_7'] = df['sales'].shift(7)    # Same day last week
df['lag_28'] = df['sales'].shift(28)  # Same day last month
```

#### **Rolling Statistics**
```python
# Trend indicators
df['roll_mean_7'] = df['sales'].rolling(7).mean()   # Weekly average
df['roll_mean_28'] = df['sales'].rolling(28).mean() # Monthly average
df['roll_std_7'] = df['sales'].rolling(7).std()     # Weekly volatility
```

#### **Categorical Encoding**
```python
# LabelEncoder for high-cardinality categoricals
item_encoder = LabelEncoder()
df['item_id_encoded'] = item_encoder.fit_transform(df['item_id'])
store_encoder = LabelEncoder()  
df['store_id_encoded'] = store_encoder.fit_transform(df['store_id'])
```

### ğŸ¯ Output YapÄ±sÄ±

#### **Model Artifacts**
```
artifacts/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ arima_FOODS_3_090.pkl      # ARIMA model object
â”‚   â”œâ”€â”€ prophet_FOODS_3_090.json   # Prophet model serialization
â”‚   â””â”€â”€ lgbm.pkl                   # LightGBM booster object
```

#### **Predictions & Reports**
```
artifacts/
â”œâ”€â”€ preds/
â”‚   â”œâ”€â”€ arima_forecast_FOODS_3_090.csv     # Single-item ARIMA predictions
â”‚   â”œâ”€â”€ prophet_forecast_FOODS_3_090.csv   # Single-item Prophet predictions
â”‚   â”œâ”€â”€ lgbm_forecast_all.csv              # Multi-item LightGBM predictions
â”‚   â”œâ”€â”€ run_YYYYMMDD.csv                   # Daily pipeline output
â”‚   â””â”€â”€ run_YYYYMMDD_summary.png           # Visual summary report
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ tscv_report.json                   # Cross-validation results
â”‚   â”œâ”€â”€ tscv_report.md                     # Human-readable CV report
â”‚   â””â”€â”€ model_comparison.json              # Model performance comparison
```

#### **Visualizations**
```
artifacts/
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ arima_FOODS_3_090_forecast.png     # ARIMA forecast plot
â”‚   â”œâ”€â”€ arima_FOODS_3_090_metrics.png      # ARIMA diagnostics
â”‚   â”œâ”€â”€ prophet_FOODS_3_090_forecast.png   # Prophet forecast plot
â”‚   â”œâ”€â”€ prophet_FOODS_3_090_components.png # Prophet decomposition
â”‚   â”œâ”€â”€ lgbm_feature_importance.png        # Feature importance plot
â”‚   â”œâ”€â”€ feature_correlations.png           # Feature correlation heatmap
â”‚   â”œâ”€â”€ feature_distributions.png          # Feature distribution plots
â”‚   â””â”€â”€ overall_daily_sales.png            # Sales trend visualization
```

## ğŸš€ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

### ğŸ“‹ Sistem Gereksinimleri

- **Python**: 3.9+ (Ã¶nerilen 3.11)
- **RAM**: Minimum 4GB (Ã¶nerilen 8GB)
- **Disk**: 2GB+ boÅŸ alan (veri + model artifacts iÃ§in)
- **OS**: Windows, macOS, Linux (Docker desteÄŸi)

### ğŸ Python Kurulum

#### **SeÃ§enek 1: Virtual Environment (Ã–nerilen)**
```bash
# Virtual environment oluÅŸtur
python -m venv venv

# Activate (macOS/Linux)
source venv/bin/activate

# Activate (Windows)
venv\Scripts\activate

# Dependencies yÃ¼kle
pip install -r requirements.txt
```

#### **SeÃ§enek 2: Conda Environment**
```bash
# Conda environment oluÅŸtur
conda create -n m5-forecast python=3.11

# Activate
conda activate m5-forecast

# Dependencies yÃ¼kle
pip install -r requirements.txt

# Prophet iÃ§in (eÄŸer pip baÅŸarÄ±sÄ±z olursa)
conda install -c conda-forge prophet
```

#### **Required Dependencies**
```txt
pandas>=2.0.0          # Data manipulation
numpy>=1.24.0          # Numerical computing  
matplotlib>=3.7.0      # Visualization
scikit-learn>=1.3.0    # Machine learning utilities
statsmodels>=0.14.0    # Statistical models (ARIMA)
prophet>=1.1.4         # Facebook Prophet
lightgbm>=4.0.0        # Gradient boosting
prefect>=3.0.0         # Workflow orchestration
pyarrow>=12.0.0        # Parquet file support
```

### ğŸ³ Docker Kurulum (Ã–nerilen Production)

#### **HÄ±zlÄ± BaÅŸlangÄ±Ã§**
```bash
# Image build et
docker build -t m5-forecast:dev .

# Pipeline'Ä± Ã§alÄ±ÅŸtÄ±r
docker run --rm -v $(pwd)/artifacts:/app/artifacts m5-forecast:dev

# SonuÃ§larÄ± kontrol et
ls -la artifacts/preds/
```

#### **Docker Compose ile**
```bash
# Tek seferlik Ã§alÄ±ÅŸtÄ±rma
docker-compose up m5-forecast

# Production mode (Prefect server ile)
docker-compose --profile production up -d

# Prefect UI eriÅŸim
open http://localhost:4200
```

#### **Volume Mounting (Ã–nemli!)**
```bash
# Data ve artifacts klasÃ¶rlerini mount et
docker run --rm \
    -v $(pwd)/data:/app/data \
    -v $(pwd)/artifacts:/app/artifacts \
    m5-forecast:dev
```

### ğŸ“Š Veri HazÄ±rlÄ±ÄŸÄ±

#### **SeÃ§enek 1: GerÃ§ek M5 Competition Verisi**
1. [M5 Competition Kaggle](https://www.kaggle.com/c/m5-forecasting-accuracy) sayfasÄ±ndan indirin
2. `data/` klasÃ¶rÃ¼ne ÅŸu dosyalarÄ± yerleÅŸtirin:
   ```
   data/
   â”œâ”€â”€ calendar.csv                    # 1969 satÄ±r, tarih ve event bilgileri
   â”œâ”€â”€ sales_train_validation.csv      # 30490 satÄ±r, CA eyaleti satÄ±ÅŸ verileri  
   â””â”€â”€ sell_prices.csv                 # 6841121 satÄ±r, fiyat bilgileri
   ```

#### **SeÃ§enek 2: Subset OluÅŸturma (HÄ±zlÄ± Test)**
```bash
# CA eyaleti, CA_1 maÄŸazasÄ±, FOODS kategorisi, top 5 Ã¼rÃ¼n
python create_m5_subset.py

# SonuÃ§: data/ klasÃ¶rÃ¼nde subset dosyalarÄ± oluÅŸur
```

#### **SeÃ§enek 3: Sentetik Veri (Development)**
```bash
# Test amaÃ§lÄ± sahte veri oluÅŸtur
python create_sample_data.py

# SonuÃ§: GerÃ§ekÃ§i trend ve seasonal pattern'li sahte satÄ±ÅŸ verisi
```

## ğŸ’» KullanÄ±m SenaryolarÄ±

### ğŸ¯ **Scenario 1: EÄŸitim ve Ã–ÄŸrenme (ModÃ¼ler YaklaÅŸÄ±m)**
```bash
# YENÄ°: ModÃ¼ler Ã§alÄ±ÅŸtÄ±rma - her modÃ¼lÃ¼ ayrÄ± ayrÄ± Ã¶ÄŸren
python run_modular.py --module P1    # Veri hazÄ±rlama ve subset oluÅŸturma
python run_modular.py --module P2    # Feature engineering pipeline
python run_modular.py --module P3    # ARIMA geleneksel yaklaÅŸÄ±m
python run_modular.py --module P4    # Prophet modern yaklaÅŸÄ±m
python run_modular.py --module P5    # LightGBM ML yaklaÅŸÄ±m
python run_modular.py --module P6    # Cross-validation analizi
python run_modular.py --module P7    # Production automation

# ESKÄ°: Legacy single-file approach (backward compatibility)
python P1_data_preparation/create_m5_subset.py
python P2_feature_engineering/feature_engineering.py
python P3_traditional_models/arima_single_item.py
python P4_modern_models/prophet_single_item.py
python P5_ml_models/lightgbm_multi_item.py
python P6_validation/time_series_cv_simple.py
python run.py                        # Full pipeline single-run
```

### ğŸš€ **Scenario 2: Production Pipeline (Automation)**
```bash
# YENÄ°: ModÃ¼ler full pipeline
python run_modular.py               # TÃ¼m modÃ¼lleri sÄ±rayla Ã§alÄ±ÅŸtÄ±r

# Prefect automation (P7 modÃ¼lÃ¼)
python run_modular.py --module P7   # Sadece automation pipeline
python P7_automation/prefect_demand_forecast.py  # Direct module call

# Production deployment setup
prefect deployment build P7_automation/prefect_demand_forecast.py:demand_forecast_flow -n daily-forecast
prefect deployment apply demand_forecast_flow-deployment.yaml
prefect agent start -q default

# Docker production
docker build -t m5-forecast:prod .
docker run --rm \
    -v $(pwd)/data:/app/data \
    -v $(pwd)/artifacts:/app/artifacts \
    m5-forecast:prod
```

### ğŸ³ **Scenario 3: Docker Deployment (Containerized)**
```bash
# Development - quick test
docker build -t m5-forecast:dev .
docker run --rm -v $(pwd)/artifacts:/app/artifacts m5-forecast:dev

# Production with full data and artifacts
docker run --rm \
    -v $(pwd)/data:/app/data \
    -v $(pwd)/artifacts:/app/artifacts \
    -e TZ=Europe/Istanbul \
    m5-forecast:dev

# Docker Compose with Prefect orchestration
docker-compose up m5-forecast                    # Single run
docker-compose --profile production up -d        # With Prefect server

# Multi-module testing
docker run --rm -v $(pwd)/artifacts:/app/artifacts m5-forecast:dev python run_modular.py --module P6
```

### ğŸ”¬ **Scenario 4: AraÅŸtÄ±rma ve Model KarÅŸÄ±laÅŸtÄ±rmasÄ±**
```bash
# Model performance karÅŸÄ±laÅŸtÄ±rmasÄ± (sadece modeling modÃ¼lleri)
python run_modular.py --module P3    # ARIMA baseline (sMAPE ~46%)
python run_modular.py --module P4    # Prophet comparison (sMAPE ~28%)  
python run_modular.py --module P5    # LightGBM benchmark (sMAPE ~33%)

# Cross-validation deep dive
python run_modular.py --module P6    # Rolling-origin CV analysis

# Feature engineering impact analysis
python run_modular.py --module P2    # Feature creation
python run_modular.py --module P5    # Feature importance in LightGBM

# Legacy direct module access (advanced users)
python P3_traditional_models/arima_single_item.py   # ARIMA deep dive
python P4_modern_models/prophet_single_item.py      # Prophet components
python P5_ml_models/lightgbm_multi_item.py         # Feature importance
python P6_validation/time_series_cv_simple.py      # CV methodology
```

### ğŸ **Scenario 5: Programmatic Usage (Python API)**
```python
# YENÄ°: ModÃ¼ler import pattern
from P1_data_preparation import create_subset
from P2_feature_engineering import create_features  
from P3_traditional_models import run_arima
from P4_modern_models import run_prophet
from P5_ml_models import run_lightgbm
from P6_validation import run_cv_simple
from P7_automation.prefect_demand_forecast import demand_forecast_flow

# Pipeline oluÅŸturma
create_subset()                              # P1: Data preparation
create_features()                           # P2: Feature engineering  
arima_results = run_arima()                 # P3: ARIMA forecasting
prophet_results = run_prophet()             # P4: Prophet forecasting
lgbm_results = run_lightgbm()              # P5: LightGBM forecasting
cv_results = run_cv_simple()               # P6: Cross-validation
flow_results = demand_forecast_flow(        # P7: Automated pipeline
    run_date='2025-01-15',
    forecast_days=7
)

# Model comparison
print(f"ARIMA sMAPE: {arima_results['smape']:.2f}%")
print(f"Prophet sMAPE: {prophet_results['smape']:.2f}%") 
print(f"LightGBM sMAPE: {lgbm_results['smape']:.2f}%")
```

### âš™ï¸ KonfigÃ¼rasyon SeÃ§enekleri

#### **Ana KonfigÃ¼rasyon** (`create_m5_subset.py`)
```python
CONFIG = {
    'state_id': 'CA',           # Eyalet seÃ§imi (CA, TX, WI)
    'store_id': 'CA_1',         # MaÄŸaza seÃ§imi (CA_1, CA_2, CA_3, CA_4)
    'category': 'FOODS',        # Kategori (FOODS, HOBBIES, HOUSEHOLD)
    'n_items': 5,               # KaÃ§ Ã¼rÃ¼n (1-10 arasÄ±)
    'validation_days': 28,      # Validation period (28 standart)
    'random_seed': 42           # Reproducibility iÃ§in
}
```

#### **Feature Engineering** (`feature_engineering.py`)
```python
FEATURE_CONFIG = {
    'lag_days': [1, 7, 28],           # Lag feature'larÄ±n gÃ¼nleri
    'rolling_windows': [7, 28],       # Rolling window boyutlarÄ±
    'seasonal_periods': [7, 365.25], # Seasonal decomposition
    'min_observations': 60           # Feature oluÅŸturma iÃ§in min gÃ¶zlem
}
```

#### **Model Hyperparameters**
```python
# ARIMA
ARIMA_CONFIG = {
    'p_range': range(0, 3),     # AR order
    'd_range': range(0, 2),     # Differencing
    'q_range': range(0, 3),     # MA order
    'information_criterion': 'aic'
}

# LightGBM  
LGBM_CONFIG = {
    'objective': 'regression',
    'learning_rate': 0.05,
    'num_leaves': 31,
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'verbose': -1
}

# Prophet
PROPHET_CONFIG = {
    'daily_seasonality': True,
    'weekly_seasonality': True, 
    'yearly_seasonality': False,
    'uncertainty_samples': 1000
}
```

## ğŸ“Š Ã‡Ä±ktÄ± Analizi ve Raporlar

### ğŸ¯ **Beklenen Performance SonuÃ§larÄ±**

Pipeline Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda tipik olarak ÅŸu performans sÄ±ralamasÄ±nÄ± gÃ¶rÃ¼rÃ¼z:

| Model | sMAPE | MAE | RMSE | Ã–zellikler |
|-------|-------|-----|------|------------|
| **Prophet** | ~28% | ~7.5 | ~12.0 | âœ… En iyi tek-Ã¼rÃ¼n performance |
| **LightGBM** | ~33% | ~8.9 | ~13.4 | âœ… Multi-item, feature importance |
| **ARIMA** | ~47% | ~12.5 | ~18.2 | âŒ Baseline, parametrik |

### ğŸ“ˆ **Output DosyasÄ± FormatlarÄ±**

#### **CSV Predictions** (Ã¶rnek: `run_20251012.csv`)
```csv
date,item_id,store_id,prediction,model
2016-04-25,FOODS_3_090,CA_1,45.2,lightgbm
2016-04-26,FOODS_3_090,CA_1,42.8,lightgbm
2016-04-27,FOODS_3_090,CA_1,38.5,lightgbm
...
```

#### **JSON Reports** (Ã¶rnek: `tscv_report.json`)
```json
{
  "method": "Time Series CV (Rolling-Origin)",
  "validation_horizon": 28,
  "n_folds": 3,
  "summary_metrics": {
    "MAE": {"mean": 8.91, "std": 0.73},
    "RMSE": {"mean": 13.44, "std": 1.12},
    "sMAPE": {"mean": 33.83, "std": 5.73}
  }
}
```

#### **Model Comparison** (Ã¶rnek: `model_comparison.json`)
```json
{
  "timestamp": "2025-01-15T09:30:45",
  "models": {
    "arima": {"smape": 46.66, "mae": 12.48, "rmse": 18.15},
    "prophet": {"smape": 27.76, "mae": 7.43, "rmse": 11.89},
    "lightgbm": {"smape": 33.38, "mae": 8.91, "rmse": 13.44}
  },
  "winner": "prophet",
  "improvement_over_baseline": "40.5%"
}
```

### ğŸ¨ **Visualization Gallery**

#### **ğŸ“Š Time Series Cross-Validation Results**
- 3-fold rolling-origin validation gÃ¶rselleÅŸtirmesi
- Her fold iÃ§in train/validation split timeline
- Metric distribution across folds

#### **ğŸ“ˆ Prophet Component Analysis**
- Trend decomposition (long-term pattern)
- Weekly seasonality (day-of-week effects)
- Holiday effects (if any)
- Uncertainty intervals (prediction confidence)

#### **ğŸ” LightGBM Feature Importance**
```python
# Top 5 features (tipik sÄ±ralama)
1. roll_mean_7     (0.35) - 7-gÃ¼nlÃ¼k moving average
2. lag_7          (0.23) - GeÃ§en haftanÄ±n aynÄ± gÃ¼nÃ¼  
3. roll_mean_28   (0.18) - 28-gÃ¼nlÃ¼k moving average
4. dow            (0.12) - Day of week effect
5. lag_1          (0.08) - DÃ¼n'Ã¼n satÄ±ÅŸ deÄŸeri
```

#### **ğŸ¯ Sales Pattern Analysis**
- Daily sales trend over time
- Seasonal decomposition (trend + seasonal + residual)
- Outlier detection and annotation
- Volume distribution by item

## ğŸ”§ Kod Mimarisi ve YapÄ±sÄ±

### ğŸ“ **ModÃ¼ler Proje Organizasyonu**
```
ğŸ“¦ hafta5/                              # Ana proje klasÃ¶rÃ¼
â”œâ”€â”€ ğŸ“š README.md                        # Bu kapsamlÄ± dokÃ¼mantasyon (1,200+ satÄ±r)
â”œâ”€â”€ ğŸ“‹ STRUCTURE.md                     # ModÃ¼ler yapÄ± detay rehberi  
â”œâ”€â”€ ğŸ³ DOCKER_README.md                 # Docker deployment rehberi
â”œâ”€â”€ ğŸ“¦ requirements.txt                 # Python dependencies
â”œâ”€â”€ ğŸ³ Dockerfile                       # Container definition (modÃ¼ler uyumlu)
â”œâ”€â”€ ğŸ³ docker-compose.yml              # Orchestration config
â”œâ”€â”€ ğŸ“œ docker-commands.sh              # Docker helper scripts
â”œâ”€â”€ ğŸ¯ run.py                          # Single-run executor (Docker uyumlu)
â”œâ”€â”€ ğŸ”§ run_modular.py                  # ModÃ¼ler pipeline runner (YENÄ°!)
â”‚
â”œâ”€â”€ ğŸ“Š P1_data_preparation/            # Veri HazÄ±rlama ModÃ¼lÃ¼
â”‚   â”œâ”€â”€ __init__.py                    # Package definition + import shortcuts
â”‚   â”œâ”€â”€ create_m5_subset.py            # M5 subset oluÅŸturma (CA_1, FOODS, 5 items)
â”‚   â””â”€â”€ create_sample_data.py          # Sentetik veri oluÅŸturma
â”‚
â”œâ”€â”€ âš™ï¸ P2_feature_engineering/         # Feature Engineering ModÃ¼lÃ¼
â”‚   â”œâ”€â”€ __init__.py                    # Package definition
â”‚   â””â”€â”€ feature_engineering.py        # Lag/rolling/seasonal features
â”‚
â”œâ”€â”€ ğŸ“ˆ P3_traditional_models/          # Geleneksel Ä°statistiksel Modeller
â”‚   â”œâ”€â”€ __init__.py                    # Package definition
â”‚   â””â”€â”€ arima_single_item.py          # ARIMA(p,d,q) with grid search
â”‚
â”œâ”€â”€ ğŸš€ P4_modern_models/               # Modern Forecasting Modelleri
â”‚   â”œâ”€â”€ __init__.py                    # Package definition
â”‚   â””â”€â”€ prophet_single_item.py        # Facebook Prophet with components
â”‚
â”œâ”€â”€ ğŸ¤– P5_ml_models/                   # Machine Learning Modelleri
â”‚   â”œâ”€â”€ __init__.py                    # Package definition
â”‚   â””â”€â”€ lightgbm_multi_item.py        # LightGBM multi-item forecasting
â”‚
â”œâ”€â”€ âœ… P6_validation/                  # Model Validation ve Cross-Validation
â”‚   â”œâ”€â”€ __init__.py                    # Package definition
â”‚   â”œâ”€â”€ time_series_cv.py             # Comprehensive CV with plots
â”‚   â””â”€â”€ time_series_cv_simple.py      # Simplified 3-fold CV
â”‚
â”œâ”€â”€ ğŸ”„ P7_automation/                  # Pipeline Automation
â”‚   â”œâ”€â”€ __init__.py                    # Package definition
â”‚   â””â”€â”€ prefect_demand_forecast.py    # Daily forecasting workflow
â”‚
â”œâ”€â”€ ğŸ“¦ legacy/                         # Legacy Files
â”‚   â””â”€â”€ m5_forecasting.py             # Original monolith implementation
â”‚
â”œâ”€â”€ ğŸ“ data/                           # M5 Dataset Files
â”‚   â”œâ”€â”€ calendar.csv                  # M5 calendar + events (1,969 days)
â”‚   â”œâ”€â”€ sales_train_CA.csv            # CA sales data subset
â”‚   â””â”€â”€ sell_prices.csv               # Price information
â”‚
â””â”€â”€ ğŸ“ artifacts/                      # Outputs ve Model Artifacts
    â”œâ”€â”€ datasets/                      # Feature engineered datasets
    â”‚   â”œâ”€â”€ train.csv, valid.csv       # Train/validation splits
    â”‚   â”œâ”€â”€ fe_train.parquet           # Feature engineered training
    â”‚   â””â”€â”€ fe_valid.parquet           # Feature engineered validation
    â”œâ”€â”€ models/                        # Trained model objects
    â”‚   â”œâ”€â”€ arima_FOODS_3_090.pkl      # ARIMA model state
    â”‚   â”œâ”€â”€ prophet_FOODS_3_090.json   # Prophet model serialization
    â”‚   â””â”€â”€ lgbm.pkl                   # LightGBM booster object
    â”œâ”€â”€ figures/                       # Visualizations gallery
    â”‚   â”œâ”€â”€ arima_*_forecast.png       # ARIMA forecasts + diagnostics
    â”‚   â”œâ”€â”€ prophet_*_components.png   # Prophet decomposition
    â”‚   â”œâ”€â”€ lgbm_feature_importance.png # Feature importance plots
    â”‚   â”œâ”€â”€ feature_correlations.png   # Feature correlation heatmap
    â”‚   â””â”€â”€ overall_daily_sales.png    # Sales trend visualization
    â”œâ”€â”€ preds/                         # Prediction outputs
    â”‚   â”œâ”€â”€ run_YYYYMMDD.csv          # Daily pipeline CSV output
    â”‚   â”œâ”€â”€ run_YYYYMMDD_summary.png  # Visual summary report
    â”‚   â””â”€â”€ *_forecast_*.csv          # Model-specific predictions
    â””â”€â”€ reports/                       # Analysis reports
        â”œâ”€â”€ tscv_report.json          # Cross-validation results
        â”œâ”€â”€ tscv_report.md            # Human-readable CV report
        â””â”€â”€ model_comparison.json     # Performance benchmarks
```

### ğŸ® **ModÃ¼ler KullanÄ±m SenaryolarÄ±**

#### **ğŸ“š EÄŸitim AmaÃ§lÄ± - AdÄ±m AdÄ±m**
```bash
# Her modÃ¼lÃ¼ ayrÄ± ayrÄ± Ã¶ÄŸren ve Ã§alÄ±ÅŸtÄ±r
python run_modular.py --module P1    # Veri hazÄ±rlama
python run_modular.py --module P2    # Feature engineering  
python run_modular.py --module P3    # ARIMA modeling
python run_modular.py --module P4    # Prophet forecasting
python run_modular.py --module P5    # LightGBM ML approach
python run_modular.py --module P6    # Cross-validation
python run_modular.py --module P7    # Production automation
```

#### **ğŸš€ Production - Full Pipeline**
```bash
# Tam pipeline - tÃ¼m modÃ¼lleri sÄ±rayla
python run_modular.py

# Docker production deployment
docker build -t m5-forecast:dev .
docker run --rm -v $(pwd)/artifacts:/app/artifacts m5-forecast:dev

# Docker Compose with Prefect server
docker-compose --profile production up -d
```

#### **ğŸ”¬ AraÅŸtÄ±rma - Specific Analysis**
```bash
# Model karÅŸÄ±laÅŸtÄ±rmasÄ± iÃ§in sadece modeling modÃ¼lleri
python run_modular.py --module P3    # ARIMA baseline
python run_modular.py --module P4    # Prophet comparison
python run_modular.py --module P5    # LightGBM benchmark

# Cross-validation deep dive
python run_modular.py --module P6    # Rolling-origin CV analysis
```

#### **ğŸ Python Import - Programmatic Usage**
```python
# ModÃ¼ler import ve kullanÄ±m
from P1_data_preparation import create_subset
from P7_automation.prefect_demand_forecast import demand_forecast_flow

# Data hazÄ±rla
create_subset()

# Automated forecasting Ã§alÄ±ÅŸtÄ±r
result = demand_forecast_flow(forecast_days=7)
print(f"Forecast generated: {result['csv_path']}")
```

### ğŸ§© **Ana ModÃ¼l YapÄ±sÄ±**

#### **P1: Data Preparation Module**
```python
class M5DatasetCreator:
    def __init__(config):           # KonfigÃ¼rasyon yÃ¼kleme
    def load_raw_data():           # M5 raw data loading
    def filter_subset():           # State/store/category filtering  
    def create_time_features():    # Basic time features
    def train_test_split():        # Time-based splitting
    def save_processed_data():     # Parquet format save
```

#### **P2: Feature Engineering Module**
```python
class TimeSeriesFeatureEngine:
    def __init__(data_df):          # Input dataframe
    def create_lag_features():      # Historical lag features
    def create_rolling_features():  # Moving averages/std
    def create_seasonal_features(): # Day/week/month encoding
    def handle_missing_values():    # Forward fill strategy
    def validate_features():        # Feature quality checks
```

#### **P3: ARIMA Module**
```python
class ARIMAForecaster:
    def __init__(series):           # Time series input
    def check_stationarity():       # ADF test implementation
    def grid_search_params():       # (p,d,q) optimization
    def fit_best_model():          # Model training
    def generate_forecast():        # Multi-step ahead prediction
    def calculate_metrics():        # Performance evaluation
    def plot_diagnostics():         # Residual analysis
```

#### **P4: Prophet Module**
```python
class ProphetForecaster:
    def __init__(config):           # Prophet configuration
    def prepare_prophet_data():     # ds/y format conversion
    def configure_seasonality():    # Daily/weekly/yearly setup
    def add_custom_regressors():    # External feature addition
    def fit_prophet_model():        # Model training
    def generate_forecast():        # Future dataframe prediction
    def extract_components():       # Trend/seasonal decomposition
```

#### **P5: LightGBM Module**
```python
class LightGBMForecaster:
    def __init__(config):           # Model hyperparameters
    def prepare_ml_features():      # Feature matrix preparation
    def encode_categoricals():      # Label encoding
    def train_model():             # Gradient boosting training
    def iterative_forecast():      # Multi-step prediction
    def analyze_feature_importance(): # SHAP/gain analysis
    def cross_validate():          # Time series CV
```

#### **P6: Cross-Validation Module**
```python
class TimeSeriesCrossValidator:
    def __init__(data, model):      # Data and model setup
    def create_rolling_splits():    # No-shuffle temporal splits
    def validate_temporal_order():  # Leakage prevention
    def run_cv_fold():             # Single fold execution
    def aggregate_results():        # Cross-fold statistics
    def statistical_tests():       # Significance testing
```

#### **P7: Pipeline Automation Module**
```python
@flow
def demand_forecast_flow():
    data = load_data_task()         # Prefect task: data loading
    features = feature_engineer_task(data)  # Feature engineering
    model = train_model_task(features)      # Model training
    preds = predict_task(model, features)   # Prediction generation
    outputs = save_outputs_task(preds)      # Results persistence
    return outputs
```

### ğŸ“ **Educational Design Patterns**

#### **Defensive Programming**
```python
# Her modÃ¼lde exception handling
try:
    import prophet
    PROPHET_AVAILABLE = True
except ImportError:
    print("âš ï¸ Prophet bulunamadÄ±, geÃ§iliyor...")
    PROPHET_AVAILABLE = False

# Graceful degradation
if not PROPHET_AVAILABLE:
    prophet_results = {"error": "Prophet not available"}
else:
    prophet_results = run_prophet_forecast()
```

#### **Configuration-Driven Development**
```python
# Tek bir yerde configuration
CONFIG = {
    'data_config': {...},
    'model_config': {...},
    'output_config': {...}
}

# Her modÃ¼l config'i inherit eder
class BaseForecaster:
    def __init__(self, config=CONFIG):
        self.config = config
```

#### **Logging and Monitoring**
```python
import logging

# Structured logging
logger = logging.getLogger(__name__)
logger.info(f"ğŸ“Š Veri yÃ¼klendi: {data.shape}")
logger.warning(f"âš ï¸ Missing values: {missing_count}")
logger.error(f"âŒ Model eÄŸitim hatasÄ±: {error}")
```

#### **Reproducibility Enforcement**
```python
# Seed management
np.random.seed(CONFIG['random_seed'])
random.seed(CONFIG['random_seed'])

# Deterministic model behavior
lgb_params = {
    'objective': 'regression',
    'random_state': CONFIG['random_seed'],
    'deterministic': True
}
```

## ğŸ¯ **EÄŸitim Hedefleri ve Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±**

### ğŸ“š **Akademik KazanÄ±mlar**

#### **Time Series Fundamentals**
- âœ… **Stationarity Testing**: ADF test ile trend detection
- âœ… **Seasonal Decomposition**: Trend + Seasonal + Residual
- âœ… **Autocorrelation Analysis**: ACF/PACF plots interpretation
- âœ… **Time-based Cross-Validation**: Temporal leakage prevention

#### **Statistical Modeling**
- âœ… **ARIMA Methodology**: Box-Jenkins approach implementation
- âœ… **Parameter Optimization**: Grid search ve information criteria
- âœ… **Model Diagnostics**: Residual analysis ve assumption testing
- âœ… **Forecast Intervals**: Uncertainty quantification

#### **Machine Learning for Time Series**
- âœ… **Feature Engineering**: Lag, rolling, seasonal features
- âœ… **Gradient Boosting**: LightGBM hyperparameter tuning
- âœ… **Multi-step Forecasting**: Iterative prediction strategy
- âœ… **Feature Importance**: SHAP values ve gain analysis

#### **Production MLOps**
- âœ… **Workflow Orchestration**: Prefect tasks ve flows
- âœ… **Containerization**: Docker multi-stage builds
- âœ… **Monitoring**: Logging ve error handling
- âœ… **Scheduling**: Cron-based automated execution

### ğŸ”¬ **Hands-on Deneyimler**

#### **Veri MÃ¼hendisliÄŸi**
```python
# M5 veri setini anlama
- 30.490 unique item-store kombinasyonu
- 1.969 gÃ¼nlÃ¼k satÄ±ÅŸ verisi (2011-2016)
- 3 eyalet (CA, TX, WI), 10 maÄŸaza, 3 kategori
- Hierarchical structure: State > Store > Category > Item
```

#### **Model KarÅŸÄ±laÅŸtÄ±rmasÄ±**
```python
# Objektif model comparison
performance_comparison = {
    'arima_vs_prophet': prophet_improvement,     # ~40% better sMAPE
    'prophet_vs_lightgbm': feature_importance,   # Rolling features critical
    'ensemble_potential': model_combination      # Weighted averaging
}
```

#### **Production Deployment**
```bash
# Container orchestration
docker-compose up --scale m5-forecast=3        # Horizontal scaling
kubectl apply -f k8s-cronjob.yaml             # Kubernetes scheduling
prefect deployment build --cron "0 9 * * *"   # Daily automation
```

## âš ï¸ **Bilinen Limitasyonlar ve Ä°yileÅŸtirme AlanlarÄ±**

### ğŸš§ **Mevcut KÄ±sÄ±tlamalar**

#### **Data Scope**
- âŒ Sadece CA eyaleti (TX, WI dahil deÄŸil)
- âŒ Tek maÄŸaza focus (CA_1 only)
- âŒ FOODS kategorisi (HOBBIES, HOUSEHOLD yok)
- âŒ 5 Ã¼rÃ¼n ile sÄ±nÄ±rlÄ± (30.490'dan sadece 5)

#### **Model Complexity**
- âŒ Ensemble methods yok (stacking, blending)
- âŒ Deep learning models yok (LSTM, Transformer)
- âŒ Hierarchical reconciliation yok
- âŒ External regressors minimal (weather, ekonomik indicators)

#### **Production Features**
- âŒ Real-time inference API yok
- âŒ Model versioning minimal
- âŒ A/B testing framework yok
- âŒ Automated retraining yok

### ğŸ¯ **Ä°yileÅŸtirme Roadmap'i**

#### **KÄ±sa Vadeli Ä°yileÅŸtirmeler (1-2 hafta)**
```python
# 1. Model diversity artÄ±rÄ±mÄ±
models_to_add = [
    'ExponentialSmoothing',  # statsmodels Holt-Winters
    'SeasonalNaive',         # Seasonal baseline
    'LinearRegression',      # Trend-based approach  
    'XGBoost'               # Alternative gradient boosting
]

# 2. Feature engineering expansion
new_features = [
    'price_features',        # Price elasticity
    'event_features',        # Calendar events impact
    'weather_features',      # Weather correlation
    'macro_features'         # Economic indicators
]

# 3. Evaluation enhancement
advanced_metrics = [
    'WAPE',                 # Weighted APE
    'MSIS',                 # Mean Scaled Interval Score
    'Directional_Accuracy',  # Up/down prediction accuracy
    'Quantile_Loss'         # Probabilistic forecasting
]
```

#### **Orta Vadeli GeliÅŸtirmeler (1-2 ay)**
```python
# 1. Hierarchical forecasting
hierarchy_implementation = {
    'level_1': 'Total_Store_Sales',
    'level_2': 'Category_Sales',  
    'level_3': 'Item_Sales',
    'reconciliation': 'bottom_up + top_down + optimal'
}

# 2. Automated model selection
automl_pipeline = {
    'hyperparameter_optimization': 'Optuna + Bayesian',
    'feature_selection': 'Recursive Feature Elimination',
    'model_selection': 'Cross-validation + early stopping',
    'ensemble_creation': 'Stacking + Blending'
}

# 3. Real-time deployment
production_api = {
    'framework': 'FastAPI + Pydantic',
    'container': 'Docker + Kubernetes',
    'monitoring': 'Prometheus + Grafana',
    'ci_cd': 'GitHub Actions + ArgoCD'
}
```

#### **Uzun Vadeli Vizyon (3-6 ay)**
```python
# 1. Deep learning integration
deep_learning_models = [
    'DeepAR',               # Amazon'un probabilistic model
    'N-BEATS',              # Neural basis expansion
    'Transformer',          # Attention-based forecasting
    'TFT'                   # Temporal Fusion Transformer
]

# 2. Multi-modal forecasting
multi_modal_inputs = {
    'time_series': 'Historical sales data',
    'text_data': 'Product descriptions, reviews',
    'image_data': 'Product images, store layouts',
    'graph_data': 'Store-item relationships'
}

# 3. Causal inference
causal_modeling = {
    'treatment_effects': 'Promo impact measurement',
    'counterfactual': 'What-if scenario analysis',
    'intervention': 'Optimal pricing strategies',
    'attribution': 'Marketing channel effectiveness'
}
```

## ğŸ”§ **Troubleshooting ve SÄ±k KarÅŸÄ±laÅŸÄ±lan Problemler**

### ğŸš¨ **Installation Issues**

#### **Prophet Installation Problems**
```bash
# Problem: Prophet binary wheels bulunamÄ±yor
# Solution 1: Conda kullan
conda install -c conda-forge prophet

# Solution 2: Build dependencies yÃ¼kle
# macOS
brew install cmake

# Ubuntu/Debian
sudo apt-get install build-essential cmake

# Windows
# Visual Studio Build Tools gerekli

# Solution 3: Alternative prophet-forecasting
pip install prophet-forecasting
```

#### **LightGBM Compilation Errors**
```bash
# Problem: OpenMP bulunamÄ±yor (macOS)
# Solution:
brew install libomp
export CC=/usr/bin/clang
export CXX=/usr/bin/clang++

# Problem: CUDA support isteniyor (GPU)
# Solution:
pip install lightgbm --install-option=--gpu

# Problem: Memory allocation error
# Solution: Virtual memory artÄ±r veya data size azalt
ulimit -v 8388608  # 8GB virtual memory limit
```

### ğŸ“Š **Data Issues**

#### **Missing M5 Data Files**
```bash
# Problem: Kaggle data files bulunamÄ±yor
# Solution 1: Manuel download
echo "1. https://www.kaggle.com/c/m5-forecasting-accuracy/data sayfasÄ±na git"
echo "2. sales_train_validation.csv, calendar.csv, sell_prices.csv indir"
echo "3. data/ klasÃ¶rÃ¼ne yerleÅŸtir"

# Solution 2: Subset kullan
python create_m5_subset.py  # HazÄ±r subset oluÅŸtur

# Solution 3: Sample data
python create_sample_data.py  # Sentetik veri
```

#### **Memory Issues with Large Dataset**
```python
# Problem: 30GB+ M5 dataset memory'ye sÄ±ÄŸmÄ±yor
# Solution 1: Chunked processing
chunk_size = 10000
for chunk in pd.read_csv('sales_train_validation.csv', chunksize=chunk_size):
    process_chunk(chunk)

# Solution 2: Parquet format kullan
df.to_parquet('data.parquet', compression='gzip')  # 10x smaller
df = pd.read_parquet('data.parquet')

# Solution 3: Data types optimize et
df['sales'] = df['sales'].astype('float32')        # 64bit -> 32bit
df['item_id'] = df['item_id'].astype('category')   # String -> Category
```

### ğŸ³ **Docker Issues**

#### **Container Build Failures**
```bash
# Problem: Docker build slow/failing
# Solution 1: Multi-stage build
FROM python:3.11-slim as builder
RUN pip install --user requirements.txt
FROM python:3.11-slim
COPY --from=builder /root/.local /root/.local

# Solution 2: Cache optimization
COPY requirements.txt .
RUN pip install -r requirements.txt  # Bu layer cache'lenir
COPY . .  # Code deÄŸiÅŸiklikleri cache'i bozar

# Solution 3: .dockerignore kullan
echo "__pycache__" >> .dockerignore
echo "*.pyc" >> .dockerignore
echo ".git" >> .dockerignore
```

#### **Volume Mount Problems**
```bash
# Problem: Artifacts persist etmiyor
# Solution: Volume permissions check
docker run --rm -v $(pwd)/artifacts:/app/artifacts \
    --user $(id -u):$(id -g) \
    m5-forecast:dev

# Problem: Data files gÃ¶rÃ¼nmÃ¼yor container'da
# Solution: Absolute path kullan
docker run --rm -v /full/path/to/data:/app/data m5-forecast:dev
```

### ğŸ”„ **Prefect Workflow Issues**

#### **Flow Execution Failures**
```python
# Problem: Task fail ediyor ama flow devam ediyor
# Solution: Explicit failure handling
@task
def safe_model_training(data):
    try:
        model = train_model(data)
        return model
    except Exception as e:
        logger.error(f"Model training failed: {e}")
        raise  # Re-raise to fail the flow

# Problem: Concurrent tasks dependency conflict
# Solution: Task dependencies explicit tanÄ±mla
@flow
def forecast_flow():
    data = load_data_task()
    features = feature_engineer_task(data, wait_for=[data])
    model = train_model_task(features, wait_for=[features])
```

#### **Scheduling Problems**
```bash
# Problem: Cron schedule Ã§alÄ±ÅŸmÄ±yor
# Solution: Timezone explicit set et
from prefect import flow
from prefect.blocks.system import DateTime

@flow
def scheduled_flow():
    pass

# Deployment ile timezone
prefect deployment build scheduled_flow.py:scheduled_flow \
    --cron "0 9 * * *" \
    --timezone "Europe/Istanbul"
```

### ğŸ“ˆ **Model Performance Issues**

#### **Poor Forecast Accuracy**
```python
# Problem: sMAPE > 50% (kÃ¶tÃ¼ performance)
# Diagnosis 1: Data quality check
data.isnull().sum()                    # Missing values
data.describe()                        # Outliers
data.plot()                           # Visual inspection

# Diagnosis 2: Feature correlation
correlation_matrix = features.corr()
high_corr = correlation_matrix[correlation_matrix > 0.9]

# Solution 1: Feature engineering improvement
new_features = [
    'sales_lag_14',                    # 2-week lag
    'sales_rolling_std_7',             # Volatility measure
    'sales_trend',                     # Linear trend
    'sales_seasonal_decompose'         # STL decomposition
]

# Solution 2: Hyperparameter tuning
from optuna import create_study
def objective(trial):
    params = {
        'learning_rate': trial.suggest_float('lr', 0.01, 0.3),
        'num_leaves': trial.suggest_int('leaves', 10, 300),
        'min_data_in_leaf': trial.suggest_int('min_data', 5, 100)
    }
    model = lgb.train(params, train_data)
    return -model.best_score['valid_0']['rmse']

study = create_study(direction='maximize')
study.optimize(objective, n_trials=100)
```

#### **Cross-Validation Inconsistency**
```python
# Problem: CV scores arasÄ±nda bÃ¼yÃ¼k variance
# Diagnosis: Fold stability check
cv_scores = [0.45, 0.28, 0.51]  # High variance
cv_std = np.std(cv_scores)      # > 0.1 problematic

# Solution 1: More folds
n_folds = 5  # Instead of 3

# Solution 2: Longer validation windows
validation_horizon = 42  # Instead of 28

# Solution 3: Overlap validation
def overlap_cv_splits(data, n_folds=5, horizon=28, overlap=0.5):
    # Each fold overlaps with previous by 50%
    pass
```

## ğŸ“š **Referanslar ve Ä°leri Okuma**

### ğŸ“– **Academic Papers**

#### **Time Series Forecasting**
- **Hyndman, R.J., & Athanasopoulos, G. (2021)**. *Forecasting: Principles and Practice* (3rd ed.)
  - ğŸ“ URL: https://otexts.com/fpp3/
  - ğŸ¯ Coverage: ARIMA, ETS, seasonal decomposition, cross-validation
  - â­ Rating: Essential time series textbook

- **Taylor, S.J., & Letham, B. (2018)**. *Forecasting at Scale*. The American Statistician, 72(1), 37-45.
  - ğŸ“ URL: https://peerj.com/preprints/3190/
  - ğŸ¯ Coverage: Prophet methodology, decomposable time series models
  - â­ Rating: Prophet original paper

#### **Machine Learning for Time Series**
- **Januschowski, T., et al. (2020)**. *Criteria for classifying forecasting methods*. International Journal of Forecasting, 36(1), 167-177.
  - ğŸ¯ Coverage: ML vs statistical methods comparison
  - â­ Rating: Methodology comparison framework

- **Oreshkin, B.N., et al. (2019)**. *N-BEATS: Neural basis expansion analysis for interpretable time series forecasting*. ICLR 2020.
  - ğŸ“ URL: https://arxiv.org/abs/1905.10437
  - ğŸ¯ Coverage: Deep learning for time series, neural basis expansion
  - â­ Rating: State-of-the-art neural forecasting

#### **Cross-Validation for Time Series**
- **Bergmeir, C., & BenÃ­tez, J.M. (2012)**. *On the use of cross-validation for time series predictor evaluation*. Information Sciences, 191, 192-213.
  - ğŸ¯ Coverage: Temporal leakage, proper CV for time series
  - â­ Rating: CV methodology for time series

### ğŸ› ï¸ **Technical Documentation**

#### **Libraries and Frameworks**
- **Prophet Documentation**: https://facebook.github.io/prophet/
  - ğŸ“– User Guide, API Reference, Case Studies
  - ğŸ”§ Installation troubleshooting, parameter tuning
  
- **LightGBM Documentation**: https://lightgbm.readthedocs.io/
  - ğŸ“– Parameter reference, Python API
  - ğŸ”§ GPU acceleration, distributed training

- **Prefect Documentation**: https://docs.prefect.io/
  - ğŸ“– Workflow orchestration, task management
  - ğŸ”§ Deployment patterns, cloud integration

- **Statsmodels Documentation**: https://www.statsmodels.org/stable/tsa.html
  - ğŸ“– Time series analysis, ARIMA implementation
  - ğŸ”§ Statistical tests, model diagnostics

#### **Dataset and Competition**
- **M5 Competition Kaggle**: https://www.kaggle.com/c/m5-forecasting-accuracy
  - ğŸ“Š Dataset download, competition leaderboard
  - ğŸ’¬ Discussion forum, winning solutions
  
- **M5 Competition Paper**: Makridakis, S., et al. (2022). *The M5 competition: Background, organization, and implementation*. International Journal of Forecasting, 38(4), 1325-1336.
  - ğŸ¯ Coverage: Competition design, evaluation metrics, lessons learned

### ğŸ“ **Online Courses and Tutorials**

#### **Time Series Forecasting**
- **Coursera: Time Series Forecasting** (University of Washington)
  - ğŸ“ URL: https://coursera.org/learn/time-series-forecasting
  - ğŸ¯ Coverage: Classical methods, ARIMA, seasonality
  - â±ï¸ Duration: 4 weeks

- **Fast.ai: Practical Deep Learning for Time Series**
  - ğŸ“ URL: https://course.fast.ai/
  - ğŸ¯ Coverage: Deep learning applications, transfer learning
  - â±ï¸ Duration: Self-paced

#### **MLOps and Production**
- **Google Cloud: MLOps Specialization**
  - ğŸ“ URL: https://coursera.org/specializations/machine-learning-engineering-for-production-mlops
  - ğŸ¯ Coverage: ML pipelines, monitoring, deployment
  - â±ï¸ Duration: 4 courses

### ğŸ† **Competition Solutions and Case Studies**

#### **M5 Competition Winners**
- **1st Place Solution**: https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/163684
  - ğŸ”§ LightGBM ensemble, feature engineering, hierarchical reconciliation
  
- **2nd Place Solution**: https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/164374
  - ğŸ”§ Multi-level modeling, uncertainty quantification

#### **Industry Case Studies**
- **Uber Forecasting**: https://eng.uber.com/forecasting-introduction/
  - ğŸ¢ Real-world scaling challenges, operational forecasting
  
- **Netflix Demand Forecasting**: https://netflixtechblog.com/forecasting-at-netflix-5ae9ea92c51d
  - ğŸ¢ Content demand prediction, recommendation systems

### ğŸ”¬ **Research Communities and Forums**

#### **Academic Communities**
- **International Institute of Forecasters**: https://forecasters.org/
  - ğŸ“š Journal access, conference proceedings
  
- **NIPS Time Series Workshop**: https://neurips.cc/
  - ğŸ”¬ Latest research, deep learning applications

#### **Practitioner Communities**
- **Stack Overflow - Time Series**: https://stackoverflow.com/questions/tagged/time-series
  - ğŸ’¬ Technical Q&A, implementation help
  
- **Reddit - Machine Learning**: https://reddit.com/r/MachineLearning
  - ğŸ’¬ Research discussions, paper reviews

- **Kaggle Learn - Time Series**: https://www.kaggle.com/learn/time-series
  - ğŸ“– Interactive tutorials, hands-on exercises

### ğŸ“Š **Datasets for Practice**

#### **Public Time Series Datasets**
- **UCR Time Series Archive**: https://www.cs.ucr.edu/~eamonn/time_series_data_2018/
  - ğŸ“Š 128 classification datasets, various domains
  
- **Federal Reserve Economic Data (FRED)**: https://fred.stlouisfed.org/
  - ğŸ“Š Economic indicators, financial time series
  
- **Google Trends**: https://trends.google.com/
  - ğŸ“Š Search volume data, cultural trends

#### **Synthetic Data Generators**
- **TSlearn Datasets**: https://tslearn.readthedocs.io/en/stable/gen_modules/tslearn.datasets.html
  - ğŸ”§ Synthetic time series with known patterns
  
- **Darts Synthetic Data**: https://unit8co.github.io/darts/
  - ğŸ”§ Configurable synthetic time series generator

---

## ğŸ“ **Proje Ã–zeti ve Migration Rehberi**

### ğŸ†• **Bu SÃ¼rÃ¼mdeki Yenilikler (v2.0)**

#### **ğŸ—ï¸ ModÃ¼ler Mimari**
- **7 Ana ModÃ¼l**: P1-P7 arasÄ± sistemli organizasyon
- **Package Structure**: Her modÃ¼lde `__init__.py` ve import shortcuts
- **Backward Compatibility**: Eski dosyalar `legacy/` klasÃ¶rÃ¼nde korundu

#### **ğŸ® Yeni Ã‡alÄ±ÅŸtÄ±rma YÃ¶ntemleri**
- **`run_modular.py`**: Module-specific execution (`--module P1`)
- **Enhanced Docker**: ModÃ¼ler yapÄ± destekli Dockerfile
- **Programmatic API**: Python import pattern iÃ§in shortcuts

#### **ğŸ“š KapsamlÄ± DokÃ¼mantasyon**
- **1,400+ satÄ±r README**: Dataset hikayesi, modÃ¼ler mimari, troubleshooting
- **STRUCTURE.md**: DetaylÄ± yapÄ±sal rehber
- **DOCKER_README.md**: Container deployment rehberi

### ğŸ”„ **Migration Rehberi (v1.0 â†’ v2.0)**

#### **Eski KullanÄ±m â†’ Yeni KullanÄ±m**
```bash
# ESKÄ° (v1.0)
python m5_forecasting.py           # Monolith approach
python arima_single_item.py        # Direct script execution

# YENÄ° (v2.0) 
python run_modular.py              # Full modular pipeline
python run_modular.py --module P3  # Specific module (ARIMA)
python P3_traditional_models/arima_single_item.py  # Direct access (korundu)
```

#### **Import Pattern DeÄŸiÅŸiklikleri**
```python
# ESKÄ° (v1.0)
from arima_single_item import main
from prefect_demand_forecast import demand_forecast_flow

# YENÄ° (v2.0)
from P3_traditional_models import run_arima  # Package level
from P7_automation.prefect_demand_forecast import demand_forecast_flow  # Module level

# FALLBACK (backward compatibility)
try:
    from P3_traditional_models import run_arima
except ImportError:
    from arima_single_item import main as run_arima  # Legacy support
```

### ğŸ“‹ **Proje KarÅŸÄ±laÅŸtÄ±rmasÄ±: Ã–nce vs Sonra**

| Ã–zellik | v1.0 (Monolith) | v2.0 (Modular) |
|---------|-----------------|-----------------|
| **Dosya SayÄ±sÄ±** | 11 Python dosyasÄ± | 7 modÃ¼l + 16 dosya |
| **Organizasyon** | Flat structure | Hierarchical modules |
| **Ã‡alÄ±ÅŸtÄ±rma** | Script-by-script | Module-by-module |
| **Import** | Direct imports | Package imports |
| **Docker** | Basic Dockerfile | Modular-aware container |
| **Documentation** | Basic README | 1,400+ line docs |
| **Testing** | Individual scripts | Module isolation |
| **Scalability** | Monolith deployment | Microservice ready |

### ğŸ¯ **Ã–ÄŸrenme YolculuÄŸu Rehberi**

#### **ğŸŒŸ Beginner Level (Hafta 1-2)**
```bash
# ModÃ¼lleri sÄ±rayla Ã¶ÄŸren
python run_modular.py --module P1    # Veri anlama
python run_modular.py --module P2    # Feature engineering
python run_modular.py --module P3    # Ä°lk model (ARIMA)
```

#### **ğŸš€ Intermediate Level (Hafta 3-4)**
```bash
# Model karÅŸÄ±laÅŸtÄ±rmasÄ±
python run_modular.py --module P4    # Prophet
python run_modular.py --module P5    # LightGBM
python run_modular.py --module P6    # Cross-validation
```

#### **ğŸ† Advanced Level (Hafta 5-6)**
```bash
# Production deployment
python run_modular.py --module P7    # Automation
docker build -t m5-forecast:dev .    # Containerization
docker-compose --profile production up -d  # Orchestration
```

### ğŸ“Š **BaÅŸarÄ± Metrikleri ve Beklentiler**

#### **Model Performance Beklentileri**
- **ARIMA**: sMAPE ~46% (Baseline istatistiksel model)
- **Prophet**: sMAPE ~28% (En iyi single-model performance)
- **LightGBM**: sMAPE ~33% (Feature engineering sayesinde)

#### **Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±**
- âœ… **Time Series Fundamentals**: Stationarity, seasonality, lag features
- âœ… **Model Comparison**: Statistical vs ML approaches
- âœ… **Production Skills**: Docker, Prefect, automated pipelines
- âœ… **Code Organization**: Modular architecture, package management

### ğŸ“ **Contribution Guidelines**

Bu proje eÄŸitim amaÃ§lÄ±dÄ±r ve katkÄ±lara aÃ§Ä±ktÄ±r. ModÃ¼ler yapÄ±da katkÄ±da bulunmak iÃ§in:

#### **ğŸ—ï¸ ModÃ¼l BazlÄ± KatkÄ±**
1. ğŸ´ Repository'yi fork edin
2. ğŸ¯ Specific module'Ã¼ seÃ§in (P1-P7)
3. ğŸŒŸ Module-specific branch oluÅŸturun (`git checkout -b P3-enhancement`)
4. ğŸ“ DeÄŸiÅŸikliklerinizi ilgili modÃ¼lde yapÄ±n
5. ğŸ§ª Module testing: `python run_modular.py --module P3`
6. ğŸ“¤ Branch'i push edin (`git push origin P3-enhancement`)
7. ğŸ”€ Pull Request oluÅŸturun

#### **ğŸ“‹ KatkÄ± AlanlarÄ±**
- **P1**: Yeni data sources, preprocessing improvements
- **P2**: Advanced feature engineering, external data
- **P3**: Alternative statistical models (ETS, TBATS)
- **P4**: Prophet hyperparameter optimization, custom regressors
- **P5**: Ensemble methods, deep learning models
- **P6**: Advanced cross-validation, statistical tests
- **P7**: Real-time deployment, monitoring, alerts

#### **ğŸ¯ Code Standards**
- Her modÃ¼le `__init__.py` ekleyin
- Import shortcuts saÄŸlayÄ±n
- Backward compatibility koruyun
- Comprehensive logging ekleyin
- Unit tests yazÄ±n (`test_P1.py`, `test_P2.py`, etc.)

### ğŸ“„ **License**

Bu proje MIT License altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±n.

### ğŸ¤ **Acknowledgments**

- **M5 Competition Organizers**: Walmart Labs, University of Nicosia
- **Library Maintainers**: Statsmodels, Prophet, LightGBM, Prefect teams
- **Educational Inspiration**: Fast.ai, Coursera Time Series courses
- **Community Support**: Kaggle community, Stack Overflow contributors

---

**âš ï¸ Disclaimer**: Bu proje eÄŸitim amaÃ§lÄ±dÄ±r. Production ortamÄ±nda kullanmadan Ã¶nce kapsamlÄ± testing, validation ve optimization yapÄ±lmasÄ± Ã¶nerilir. Financial ve business critical kararlar iÃ§in profesyonel danÄ±ÅŸmanlÄ±k alÄ±nmalÄ±dÄ±r.
#!/usr/bin/env python3
"""
M5 Veri Seti KÃ¼Ã§Ã¼k Ã‡alÄ±ÅŸma Seti Ãœretici

Bu script M5 veri setinden kÃ¼Ã§Ã¼k bir alt-kÃ¼me oluÅŸturur:
- CA eyaleti, CA_1 maÄŸazasÄ±, FOODS kategorisi
- En yÃ¼ksek satÄ±ÅŸlÄ± 5 Ã¼rÃ¼n
- GÃ¼nlÃ¼k zaman serisi formatÄ±nda
- Train/Validation split (son 28 gÃ¼n validation)

KullanÄ±m: python create_m5_subset.py
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
from datetime import datetime

def create_m5_subset():
    """M5 veri setinden kÃ¼Ã§Ã¼k Ã§alÄ±ÅŸma seti oluÅŸtur"""
    
    print("ğŸ¯ M5 KÃ¼Ã§Ã¼k Ã‡alÄ±ÅŸma Seti OluÅŸturucu")
    print("=" * 50)
    
    # Ã‡Ä±ktÄ± klasÃ¶rlerini oluÅŸtur
    os.makedirs('./artifacts/datasets', exist_ok=True)
    os.makedirs('./artifacts/figures', exist_ok=True)
    
    # 1. Veri dosyalarÄ±nÄ± oku
    print("\nğŸ“ 1. Veri dosyalarÄ± okunuyor...")
    
    try:
        # Sales verisi
        print("   â€¢ sales_train_validation.csv okunuyor...")
        sales_df = pd.read_csv('./data/sales_train_validation.csv')
        print(f"   âœ“ SatÄ±ÅŸ verisi: {sales_df.shape}")
        
        # Calendar verisi
        print("   â€¢ calendar.csv okunuyor...")
        calendar_df = pd.read_csv('./data/calendar.csv')
        calendar_df['date'] = pd.to_datetime(calendar_df['date'])
        print(f"   âœ“ Takvim verisi: {calendar_df.shape}")
        
        # Prices verisi (opsiyonel, kullanmayacaÄŸÄ±z ama kontrol edelim)
        try:
            prices_df = pd.read_csv('./data/sell_prices.csv')
            print(f"   âœ“ Fiyat verisi: {prices_df.shape}")
        except FileNotFoundError:
            print("   âš ï¸  Fiyat verisi bulunamadÄ± (isteÄŸe baÄŸlÄ±)")
            
    except FileNotFoundError as e:
        print(f"   âŒ Veri dosyasÄ± bulunamadÄ±: {e}")
        print("   ğŸ’¡ Ã–nce create_sample_data.py Ã§alÄ±ÅŸtÄ±rÄ±n veya gerÃ§ek M5 verisini indirin")
        return
    
    # 2. CA_1 maÄŸazasÄ± ve FOODS kategorisini filtrele
    print("\nğŸª 2. CA_1 maÄŸazasÄ± ve FOODS kategorisi filtreleniyor...")
    
    # CA_1 maÄŸazasÄ± filtresi
    ca1_mask = (sales_df['store_id'] == 'CA_1')
    ca1_sales = sales_df[ca1_mask].copy()
    print(f"   â€¢ CA_1 maÄŸazasÄ± Ã¼rÃ¼n sayÄ±sÄ±: {len(ca1_sales)}")
    
    # FOODS kategorisi filtresi
    # M5'te kategori 'cat_id' sÃ¼tununda, FOODS genelde FOODS ile baÅŸlar
    foods_mask = ca1_sales['cat_id'].str.contains('FOOD', case=False, na=False)
    foods_sales = ca1_sales[foods_mask].copy()
    print(f"   â€¢ FOODS kategorisi Ã¼rÃ¼n sayÄ±sÄ±: {len(foods_sales)}")
    
    if len(foods_sales) == 0:
        print("   âš ï¸  FOODS kategorisi bulunamadÄ±, tÃ¼m kategorileri kullanÄ±yoruz...")
        foods_sales = ca1_sales.copy()
    
    # 3. En yÃ¼ksek satÄ±ÅŸlÄ± 5 Ã¼rÃ¼nÃ¼ bul
    print("\nğŸ“Š 3. En yÃ¼ksek satÄ±ÅŸlÄ± 5 Ã¼rÃ¼n bulunuyor...")
    
    # SatÄ±ÅŸ sÃ¼tunlarÄ±nÄ± al (d_1, d_2, ... formatÄ±nda)
    sales_cols = [col for col in foods_sales.columns if col.startswith('d_')]
    print(f"   â€¢ Toplam {len(sales_cols)} gÃ¼n verisi mevcut")
    
    # Her Ã¼rÃ¼n iÃ§in toplam satÄ±ÅŸÄ± hesapla
    foods_sales['total_sales'] = foods_sales[sales_cols].sum(axis=1)
    
    # En yÃ¼ksek satÄ±ÅŸlÄ± 5 Ã¼rÃ¼nÃ¼ seÃ§
    top5_items = foods_sales.nlargest(5, 'total_sales')
    
    print("   â€¢ En yÃ¼ksek satÄ±ÅŸlÄ± 5 Ã¼rÃ¼n:")
    for i, (_, item) in enumerate(top5_items.iterrows(), 1):
        print(f"     {i}. {item['item_id']} (Total: {item['total_sales']:,.0f})")
    
    # 4. GÃ¼nlÃ¼k zaman serisi oluÅŸtur (uzun format)
    print("\nğŸ“ˆ 4. GÃ¼nlÃ¼k zaman serisi oluÅŸturuluyor...")
    
    # Sadece top 5 Ã¼rÃ¼nÃ¼ al
    selected_items = top5_items[['id', 'item_id', 'store_id', 'state_id'] + sales_cols].copy()
    
    # Uzun formata Ã§evir
    long_data = []
    
    for _, item_row in selected_items.iterrows():
        item_id = item_row['item_id']
        store_id = item_row['store_id']
        
        # Her gÃ¼n iÃ§in satÄ±ÅŸ verisi
        for d_col in sales_cols:
            sales_value = item_row[d_col]
            
            # NaN deÄŸerleri 0 yap
            if pd.isna(sales_value):
                sales_value = 0
            
            long_data.append({
                'item_id': item_id,
                'store_id': store_id,
                'd': d_col,
                'sales': int(sales_value)
            })
    
    # DataFrame'e Ã§evir
    long_df = pd.DataFrame(long_data)
    
    # Calendar ile birleÅŸtir (tarih bilgisi iÃ§in)
    long_df = long_df.merge(calendar_df[['d', 'date']], on='d', how='left')
    
    # Tarih sÄ±ralamasÄ±
    long_df = long_df.sort_values(['item_id', 'date']).reset_index(drop=True)
    
    print(f"   âœ“ Uzun format veri: {long_df.shape}")
    print(f"   â€¢ Tarih aralÄ±ÄŸÄ±: {long_df['date'].min()} - {long_df['date'].max()}")
    print(f"   â€¢ Toplam gÃ¼n sayÄ±sÄ±: {long_df['date'].nunique()}")
    
    # 5. Eksik gÃ¼nleri 0 ile doldur
    print("\nğŸ”§ 5. Eksik gÃ¼nler kontrol ediliyor ve dolduruluyor...")
    
    # Her Ã¼rÃ¼n iÃ§in tam tarih aralÄ±ÄŸÄ± oluÅŸtur
    all_dates = pd.date_range(start=long_df['date'].min(), 
                             end=long_df['date'].max(), 
                             freq='D')
    
    complete_data = []
    
    for item_id in long_df['item_id'].unique():
        item_data = long_df[long_df['item_id'] == item_id].copy()
        store_id = item_data['store_id'].iloc[0]
        
        # Eksik tarihleri bul
        existing_dates = set(item_data['date'])
        missing_dates = [d for d in all_dates if d not in existing_dates]
        
        if missing_dates:
            print(f"   â€¢ {item_id}: {len(missing_dates)} eksik gÃ¼n dolduruldu")
            
            # Eksik gÃ¼nleri ekle
            for missing_date in missing_dates:
                complete_data.append({
                    'item_id': item_id,
                    'store_id': store_id,
                    'date': missing_date,
                    'sales': 0
                })
        
        # Mevcut verileri ekle
        for _, row in item_data.iterrows():
            complete_data.append({
                'item_id': row['item_id'],
                'store_id': row['store_id'],
                'date': row['date'],
                'sales': row['sales']
            })
    
    # Tam veri seti
    complete_df = pd.DataFrame(complete_data)
    complete_df = complete_df.sort_values(['item_id', 'date']).reset_index(drop=True)
    
    print(f"   âœ“ Tam veri seti: {complete_df.shape}")
    
    # 6. Train/Validation split
    print("\nâœ‚ï¸ 6. Train/Validation bÃ¶lÃ¼nmesi yapÄ±lÄ±yor...")
    
    # TÃ¼m tarihleri al ve sÄ±rala
    all_dates_sorted = sorted(complete_df['date'].unique())
    
    # Son 28 gÃ¼nÃ¼ validation, geri kalanÄ±nÄ± train yap
    validation_days = 28
    
    if len(all_dates_sorted) <= validation_days:
        print(f"   âš ï¸  Yeterli veri yok. Toplam {len(all_dates_sorted)} gÃ¼n, {validation_days} gÃ¼n validation gerekli")
        validation_days = max(1, len(all_dates_sorted) // 4)  # %25'ini validation yap
        print(f"   â€¢ Validation gÃ¼n sayÄ±sÄ± {validation_days} olarak ayarlandÄ±")
    
    # Tarih sÄ±nÄ±rlarÄ±
    split_date = all_dates_sorted[-validation_days]
    train_end_date = all_dates_sorted[-validation_days-1] if len(all_dates_sorted) > validation_days else all_dates_sorted[0]
    
    # Train ve validation setleri
    train_df = complete_df[complete_df['date'] <= train_end_date].copy()
    valid_df = complete_df[complete_df['date'] >= split_date].copy()
    
    print(f"   â€¢ Train: {train_df['date'].min()} - {train_df['date'].max()} ({len(train_df)} satÄ±r)")
    print(f"   â€¢ Valid: {valid_df['date'].min()} - {valid_df['date'].max()} ({len(valid_df)} satÄ±r)")
    
    # Index'i tarih yap
    train_df = train_df.set_index('date')
    valid_df = valid_df.set_index('date')
    
    # 7. Ã‡Ä±ktÄ±larÄ± kaydet
    print("\nğŸ’¾ 7. SonuÃ§lar kaydediliyor...")
    
    # CSV dosyalarÄ±
    train_path = './artifacts/datasets/train.csv'
    valid_path = './artifacts/datasets/valid.csv'
    
    train_df.to_csv(train_path)
    valid_df.to_csv(valid_path)
    
    print(f"   âœ“ Train verisi: {train_path}")
    print(f"   âœ“ Valid verisi: {valid_path}")
    
    # 8. GÃ¶rselleÅŸtirme
    print("\nğŸ“Š 8. GÃ¼nlÃ¼k toplam satÄ±ÅŸ grafiÄŸi oluÅŸturuluyor...")
    
    # GÃ¼nlÃ¼k toplam satÄ±ÅŸ hesapla
    daily_total = complete_df.groupby('date')['sales'].sum().reset_index()
    
    # Grafik oluÅŸtur
    plt.figure(figsize=(15, 8))
    
    # Train ve validation bÃ¶lgelerini ayÄ±r
    train_dates = train_df.reset_index()['date'].unique()
    valid_dates = valid_df.reset_index()['date'].unique()
    
    train_total = daily_total[daily_total['date'].isin(train_dates)]
    valid_total = daily_total[daily_total['date'].isin(valid_dates)]
    
    # Train verisi
    plt.plot(train_total['date'], train_total['sales'], 
             label='Train', color='blue', linewidth=2)
    
    # Validation verisi
    plt.plot(valid_total['date'], valid_total['sales'], 
             label='Validation', color='red', linewidth=2)
    
    # Split Ã§izgisi
    plt.axvline(x=split_date, color='gray', linestyle='--', alpha=0.7, 
                label=f'Train/Valid Split ({split_date.strftime("%Y-%m-%d")})')
    
    # Grafik dÃ¼zenlemeleri
    plt.title('M5 SeÃ§ilen 5 ÃœrÃ¼n - GÃ¼nlÃ¼k Toplam SatÄ±ÅŸ\n' + 
              f'CA_1 MaÄŸazasÄ±, FOODS Kategorisi', fontsize=16, fontweight='bold')
    plt.xlabel('Tarih', fontsize=12)
    plt.ylabel('GÃ¼nlÃ¼k Toplam SatÄ±ÅŸ', fontsize=12)
    plt.legend(fontsize=12)
    plt.grid(True, alpha=0.3)
    
    # X ekseni etiketlerini dÃ¶ndÃ¼r
    plt.xticks(rotation=45)
    
    # Layout ayarla
    plt.tight_layout()
    
    # Kaydet
    figure_path = './artifacts/figures/overall_daily_sales.png'
    plt.savefig(figure_path, dpi=300, bbox_inches='tight')
    print(f"   âœ“ Grafik: {figure_path}")
    
    plt.close()
    
    # 9. Ã–zet bilgiler
    print("\nğŸ“‹ Ã–ZET BÄ°LGÄ°LER")
    print("=" * 50)
    print(f"â€¢ SeÃ§ilen Ã¼rÃ¼nler: {', '.join(complete_df['item_id'].unique())}")
    print(f"â€¢ Toplam gÃ¼n sayÄ±sÄ±: {len(all_dates_sorted)}")
    print(f"â€¢ Train gÃ¼n sayÄ±sÄ±: {len(train_df.reset_index()['date'].unique())}")
    print(f"â€¢ Validation gÃ¼n sayÄ±sÄ±: {len(valid_df.reset_index()['date'].unique())}")
    print(f"â€¢ Ortalama gÃ¼nlÃ¼k satÄ±ÅŸ: {daily_total['sales'].mean():.1f}")
    print(f"â€¢ Maksimum gÃ¼nlÃ¼k satÄ±ÅŸ: {daily_total['sales'].max()}")
    print(f"â€¢ Minimum gÃ¼nlÃ¼k satÄ±ÅŸ: {daily_total['sales'].min()}")
    
    # ÃœrÃ¼n bazÄ±nda istatistikler
    print(f"\nğŸ“Š ÃœRÃœN BAZINDA Ä°STATÄ°STÄ°KLER:")
    item_stats = complete_df.groupby('item_id')['sales'].agg(['sum', 'mean', 'std', 'max']).round(2)
    for item_id, stats in item_stats.iterrows():
        print(f"â€¢ {item_id}: Toplam={stats['sum']:,.0f}, Ort={stats['mean']:.1f}, "
              f"Std={stats['std']:.1f}, Max={stats['max']:.0f}")
    
    print(f"\nâœ… Ä°ÅŸlem tamamlandÄ±!")
    print(f"ğŸ“ Ã‡Ä±ktÄ±lar: ./artifacts/ klasÃ¶rÃ¼nde")
    
    return train_df, valid_df, daily_total

if __name__ == "__main__":
    try:
        train_data, valid_data, daily_sales = create_m5_subset()
        print(f"\nğŸ‰ M5 kÃ¼Ã§Ã¼k Ã§alÄ±ÅŸma seti baÅŸarÄ±yla oluÅŸturuldu!")
        
    except Exception as e:
        print(f"\nâŒ Hata: {e}")
        import traceback
        traceback.print_exc()